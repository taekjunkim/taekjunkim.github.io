






<!doctype html>
<html
  lang="en"
  dir="ltr"
  class="scroll-smooth"
  data-default-appearance="light"
  data-auto-appearance="true"
><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="#FFFFFF" />
  
  <title>Visual functions of primate area V4 &middot; Taekjun Kim</title>
    <meta name="title" content="Visual functions of primate area V4 &middot; Taekjun Kim" />
  
  
  
  
  
  <script
    type="text/javascript"
    src="/js/appearance.min.8a082f81b27f3cb2ee528df0b0bdc39787034cf2cc34d4669fbc9977c929023c.js"
    integrity="sha256-iggvgbJ/PLLuUo3wsL3Dl4cDTPLMNNRmn7yZd8kpAjw="
  ></script>
  
  
  
  
  
  
  
    
  
  
  <link
    type="text/css"
    rel="stylesheet"
    href="/css/main.bundle.min.bb20018254d048642b9bb4d07c490f792d638246be64872943e3fefe8ef7c064.css"
    integrity="sha256-uyABglTQSGQrm7TQfEkPeS1jgka&#43;ZIcpQ&#43;P&#43;/o73wGQ="
  />
  
    
    
    
  
  
  
    
    
  
  
  
  
    
    <script
      defer
      type="text/javascript"
      id="script-bundle"
      src="/js/main.bundle.min.af5d9722112bedac95702865c340bcd6286c4e9b2c15ce26b531ea1fba974cb8.js"
      integrity="sha256-r12XIhEr7ayVcChlw0C81ihsTpssFc4mtTHqH7qXTLg="
      data-copy="Copy"
      data-copied="Copied"
    ></script>
  
  
  <meta
    name="description"
    content="
      
        Anitha Pasupathy, Dina V Popovkina, Taekjun Kim Annual Review of Vision Science
      
    "
  />
  
  
  
  <link rel="canonical" href="http://localhost:1313/publications/annurevvissci_2020/" />
  
  
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
    <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  
  <meta property="og:url" content="http://localhost:1313/publications/annurevvissci_2020/">
  <meta property="og:site_name" content="Taekjun Kim">
  <meta property="og:title" content="Visual functions of primate area V4">
  <meta property="og:description" content="Anitha Pasupathy, Dina V Popovkina, Taekjun Kim Annual Review of Vision Science">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="publications">
    <meta property="article:published_time" content="2020-09-15T00:00:00+00:00">
    <meta property="article:modified_time" content="2020-09-15T00:00:00+00:00">
    <meta property="article:tag" content="Primate">
    <meta property="article:tag" content="Electrophysiology">
    <meta property="article:tag" content="Area V4">
    <meta property="article:tag" content="Vision">
    <meta property="article:tag" content="Neuroscience">
    <meta property="article:tag" content="Review">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Visual functions of primate area V4">
  <meta name="twitter:description" content="Anitha Pasupathy, Dina V Popovkina, Taekjun Kim Annual Review of Vision Science">

  
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Selected publications",
    "name": "Visual functions of primate area V4",
    "headline": "Visual functions of primate area V4",
    
    "abstract": "Anitha Pasupathy, Dina V Popovkina, Taekjun Kim \u003ccode\u003eAnnual Review of Vision Science\u003c\/code\u003e",
    "inLanguage": "en",
    "url" : "http:\/\/localhost:1313\/publications\/annurevvissci_2020\/",
    "author" : {
      "@type": "Person",
      "name": "Taekjun Kim"
    },
    "copyrightYear": "2020",
    "dateCreated": "2020-09-15T00:00:00\u002b00:00",
    "datePublished": "2020-09-15T00:00:00\u002b00:00",
    
    "dateModified": "2020-09-15T00:00:00\u002b00:00",
    
    "keywords": ["Primate","Electrophysiology","area V4","Vision","Neuroscience","Review","Perception","Object recognition"],
    
    "mainEntityOfPage": "true",
    "wordCount": "1815"
  }
  </script>
    
    <script type="application/ld+json">
    {
   "@context": "https://schema.org",
   "@type": "BreadcrumbList",
   "itemListElement": [
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/",
       "name": "",
       "position": 1
     },
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/publications/",
       "name": "Selected Publications",
       "position": 2
     },
     {
       "@type": "ListItem",
       "name": "Visual Functions of Primate Area V4",
       "position": 3
     }
   ]
 }
  </script>

  
  <meta name="author" content="Taekjun Kim" />
  
    
      <link href="mailto:taekjunkim1223@gmail.com" rel="me" />
    
      <link href="https://github.com/taekjunkim" rel="me" />
    
      <link href="https://linkedin.com/in/taekjun-kim" rel="me" />
    
      <link href="https://scholar.google.com/citations?user=pP442rIAAAAJ&amp;hl=en" rel="me" />
    
  
  
  






  
  

  
  

</head>
<body
    class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"
  >
    <div id="the-top" class="absolute flex self-center">
      <a
        class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600"
        href="#main-content"
        ><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span
        >Skip to main content</a
      >
    </div>
    
    
      <header class="py-6 font-semibold text-neutral-900 dark:text-neutral sm:py-10 print:hidden">
  <nav class="flex items-start justify-between sm:items-center">
    
    <div class="flex flex-row items-center">
      
  <a
    class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
    rel="me"
    href="/"
    >Taekjun Kim</a
  >

    </div>
    
    
      <ul class="flex list-none flex-col text-end sm:flex-row">
        
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/about/"
                  title=""
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >About Me</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/posts/"
                  title="Posts"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Posts</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/publications/"
                  title="Selected publications"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Publications</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/tags/"
                  title="Tags"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Tags</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                
                
                  <button
                    id="search-button-1"
                    title="Search (/)"
                  >
                    
                      <span
                        class="group-dark:hover:text-primary-400 transition-colors group-hover:text-primary-600"
                      ><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></span><span
                        class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                        ></span
                      >
                    
                  </button>
                
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                
                <button
                  id="appearance-switcher-1"
                  type="button"
                  aria-label="appearance switcher"
                >
                  <span
                    class="group-dark:hover:text-primary-400 inline transition-colors group-hover:text-primary-600 dark:hidden"
                    title="Switch to dark appearance"
                  >
                    <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>
</span><span
                        class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                        ></span
                      >
                    
                  </span>
                  <span
                    class="group-dark:hover:text-primary-400 hidden transition-colors group-hover:text-primary-600 dark:inline"
                    title="Switch to light appearance"
                  >
                    
                      <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>
</span>
                    
                    
                      <span
                        class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                        ></span
                      >
                    
                  </span>
                </button>
              
            </li>
          
            
              
          
        
      </ul>
    
  </nav>
</header>

    
    <div class="relative flex grow flex-col">
      <main id="main-content" class="grow">
        
  <article>
    <header class="max-w-prose">
      
        <ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden">
  
  
    
  
    
  
  <li class="hidden inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="/"
      ></a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class=" inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="/publications/"
      >Selected publications</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="hidden inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="/publications/annurevvissci_2020/"
      >Visual functions of primate area V4</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

</ol>


      
      <h1 class="mb-8 mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
        Visual functions of primate area V4
      </h1>
      
        <div class="mb-10 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
          





  
  



  

  
  
    
  

  

  

  
    
  

  


  <div class="flex flex-row flex-wrap items-center">
    
    
      <time datetime="2020-09-15 00:00:00 &#43;0000 UTC">15 September 2020</time><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">9 mins</span>
    

    
    
  </div>

  
  
    <div class="my-1 flex flex-wrap text-xs leading-relaxed text-neutral-500 dark:text-neutral-400">
      
        
      
        
          
            <a
              href="/tags/primate/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Primate</a
            >
          
            <a
              href="/tags/electrophysiology/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Electrophysiology</a
            >
          
            <a
              href="/tags/area-v4/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Area V4</a
            >
          
            <a
              href="/tags/vision/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Vision</a
            >
          
            <a
              href="/tags/neuroscience/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Neuroscience</a
            >
          
            <a
              href="/tags/review/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Review</a
            >
          
            <a
              href="/tags/perception/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Perception</a
            >
          
            <a
              href="/tags/object-recognition/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Object Recognition</a
            >
          
        
      
    </div>
  


        </div>
      
      
    </header>
    <section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row">
      
        <div class="order-first px-0 lg:order-last lg:max-w-xs lg:ps-8">
          <div class="toc pe-5 lg:sticky lg:top-10 print:hidden">
            <details open class="-ms-5 mt-0 overflow-hidden rounded-lg ps-5">
  <summary
    class="block cursor-pointer bg-neutral-100 py-1 ps-5 text-lg font-semibold text-neutral-800 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden"
  >
    Table of Contents
  </summary>
  <div class="border-s border-dotted border-neutral-300 py-2 ps-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#article-info">Article info</a></li>
    <li><a href="#abstract">Abstract</a></li>
    <li><a href="#figures">Figures</a>
      <ul>
        <li><a href="#fig1-interconnections-between-v4-and-other-brain-regions">Fig1. Interconnections between V4 and other brain regions</a></li>
        <li><a href="#fig2-distribution-of-response-onset-latencies-of-v4-neurons">Fig2. Distribution of response onset latencies of V4 neurons</a></li>
        <li><a href="#fig3-position-invariant-tuning-for-boundary-conformation-in-v4">Fig3. Position-invariant tuning for boundary conformation in V4</a></li>
        <li><a href="#fig4-object-centered-tuning-for-boundary-conformation-in-v4">Fig4. Object-centered tuning for boundary conformation in V4</a></li>
        <li><a href="#fig5-representation-of-real-but-not-accidental-object-boundaries-in-v4">Fig5. Representation of real but not accidental object boundaries in V4</a></li>
        <li><a href="#fig6-joint-encoding-of-multiple-features-for-object-segmentation">Fig6. Joint encoding of multiple features for object segmentation</a></li>
        <li><a href="#fig7-goal-oriented-representations">Fig7. Goal-oriented representations</a></li>
        <li><a href="#fig8-interactions-between-the-visual-and-frontal-cortex-during-shape-discrimination">Fig8. Interactions between the visual and frontal cortex during shape discrimination</a></li>
        <li><a href="#fig9-memory-encoding-in-v4">Fig9. Memory encoding in V4</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</details>

          </div>
        </div>
      
      <div class="min-h-0 min-w-0 max-w-prose grow">
        <h2 id="article-info" class="relative group">Article info <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#article-info" aria-label="Anchor">#</a></span></h2><table>
  <thead>
      <tr>
          <th></th>
          <th></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>Authors</code></td>
          <td>Anitha Pasupathy, Dina V Popovkina, Taekjun Kim</td>
      </tr>
      <tr>
          <td><code>Publication date</code></td>
          <td>2020/09/15</td>
      </tr>
      <tr>
          <td><code>Journal</code></td>
          <td>Annual Review of Vision Science</td>
      </tr>
      <tr>
          <td><code>DOI</code></td>
          <td><a href="https://doi.org/10.1146/annurev-vision-030320-041306" target="_blank" rel="noreferrer">https://doi.org/10.1146/annurev-vision-030320-041306</a></td>
      </tr>
  </tbody>
</table>
<h2 id="abstract" class="relative group">Abstract <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#abstract" aria-label="Anchor">#</a></span></h2><p>Area V4—the focus of this review—is a mid-level processing stage along the ventral visual pathway of the macaque monkey. V4 is extensively interconnected with other visual cortical areas along the ventral and dorsal visual streams, with frontal cortical areas, and with several subcortical structures. Thus, it is well poised to play a broad and integrative role in visual perception and recognition—the functional domain of the ventral pathway. Neurophysiological studies in monkeys engaged in passive fixation and behavioral tasks suggest that V4 responses are dictated by tuning in a high-dimensional stimulus space defined by form, texture, color, depth, and other attributes of visual stimuli. This high-dimensional tuning may underlie the development of object-based representations in the visual cortex that are critical for tracking, recognizing, and interacting with objects. Neurophysiological and lesion studies also suggest that V4 responses are important for guiding perceptual decisions and higher-order behavior.</p>
<h2 id="figures" class="relative group">Figures <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#figures" aria-label="Anchor">#</a></span></h2><h3 id="fig1-interconnections-between-v4-and-other-brain-regions" class="relative group">Fig1. Interconnections between V4 and other brain regions <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig1-interconnections-between-v4-and-other-brain-regions" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
      <img
        width="3771"
        height="1611"
        class="mx-auto my-0 rounded-md"
        alt="Fig1"
        loading="lazy" decoding="async"
        
          src="/publications/annurevvissci_2020/Fig1_hu_32cd0aff9bfaa633.gif"
          srcset="/publications/annurevvissci_2020/Fig1_hu_d938e7127a9281b9.gif 330w,/publications/annurevvissci_2020/Fig1_hu_32cd0aff9bfaa633.gif 660w
          
            ,/publications/annurevvissci_2020/Fig1_hu_3622f4f98b0aff78.gif 1024w
          
          
            ,/publications/annurevvissci_2020/Fig1_hu_ca16dea9372b5aec.gif 1320w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
Areas connected with V4 are highlighted on the lateral surface of the macaque monkey brain. (<strong>a</strong>) Visual cortical areas along the ventral stream, many along the dorsal visual stream and frontal areas, and (<strong>b</strong>) the medial temporal lobe and many subcortical structures are interconnected with V4. Figure created using data from Felleman &amp; Van Essen (1991), Parker (2007), Ungerleider et al. (2008), Gattass et al. (2014), and Ninomiya et al. (2012a,b). Part of the figure was adapted with permission from Pasupathy et al. (2018). Abbreviations: AIT, anterior inferotemporal area; CIT, central inferotemporal area; DP, dorsal prelunate area; DR, dorsal raphe; FEF, frontal eye field; FST, fundus of the superior temporal sulcus area; IP, intraparietal areas; LC, locus coeruleus; LGN, lateral geniculate nucleus; MR, medial raphe; MST, medial superior temporal area; MT, middle temporal area; nbM, basal nucleus of Meynert; PIP, posterior intraparietal area; PIT, posterior inferotemporal area; PO, parieto-occipital area; R, thalamic reticular formation; SC, superior colliculus; V3a, visual complex V3 part A; V4t, V4 transition zone; vlPFC, ventrolateral prefrontal cortex; VT, ventral tegmentum.
</font></p>
<h3 id="fig2-distribution-of-response-onset-latencies-of-v4-neurons" class="relative group">Fig2. Distribution of response onset latencies of V4 neurons <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig2-distribution-of-response-onset-latencies-of-v4-neurons" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
      <img
        width="2510"
        height="1373"
        class="mx-auto my-0 rounded-md"
        alt="Fig2"
        loading="lazy" decoding="async"
        
          src="/publications/annurevvissci_2020/Fig2_hu_d159dc6a5e0750fa.gif"
          srcset="/publications/annurevvissci_2020/Fig2_hu_3e9c78c24e92b810.gif 330w,/publications/annurevvissci_2020/Fig2_hu_d159dc6a5e0750fa.gif 660w
          
            ,/publications/annurevvissci_2020/Fig2_hu_f45633051b9b4670.gif 1024w
          
          
            ,/publications/annurevvissci_2020/Fig2_hu_dd0931293b07cc0.gif 1320w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
(<strong>a</strong>) Onset latencies of 276 V4 neurons from three monkeys. Latency measurements were based on the responses of single V4 neurons in animals engaged in a passive fixation task. As animals fixated a variety of shape stimuli were presented within the receptive field of the cell under study. Peristimulus time histograms (PSTHs) were constructed based on evoked responses of each neuron and onset latencies were calculated based on the half-height method, i.e., as the time point at which the PSTH exceeded the mean of the peak and baseline rates. Onset latencies ranged from 25 ms to 200 ms; mean latency was 76.6 ms. For further details, see Zamarashkina et al. (2020). (<strong>b</strong>) PSTHs of two example V4 neurons studied during passive fixation, displaying approximately 100 ms difference in onset latency. PSTHs were aligned on stimulus onset and smoothed with a Gaussian kernel (σ = 4 ms).
</font></p>
<h3 id="fig3-position-invariant-tuning-for-boundary-conformation-in-v4" class="relative group">Fig3. Position-invariant tuning for boundary conformation in V4 <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig3-position-invariant-tuning-for-boundary-conformation-in-v4" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
      <img
        width="3792"
        height="2313"
        class="mx-auto my-0 rounded-md"
        alt="Fig3"
        loading="lazy" decoding="async"
        
          src="/publications/annurevvissci_2020/Fig3_hu_5d853d060766f907.gif"
          srcset="/publications/annurevvissci_2020/Fig3_hu_7745a09714e9152b.gif 330w,/publications/annurevvissci_2020/Fig3_hu_5d853d060766f907.gif 660w
          
            ,/publications/annurevvissci_2020/Fig3_hu_76755f43a8185af6.gif 1024w
          
          
            ,/publications/annurevvissci_2020/Fig3_hu_6dc2636ba5f53b61.gif 1320w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
(<strong>a</strong>) Examples of tuning for boundary conformation. Responses of two example V4 neurons (top and bottom) to simple 2D shapes recorded in a fixating animal (for further details, see Kim et al. 2019a). Response frequency histograms (right) show that the shape stimuli evoked a broad range of responses from both neurons. The 20 shapes that evoked the strongest (PREF, red) and weakest (NPREF, blue) responses are shown for each neuron (left). For the top neuron, all of the preferred shapes included a medium-sharp convex feature to the upper right; shapes that evoked a weak response did not include this feature (compare PREF and NPREF shapes). For the second neuron, preferred but not nonpreferred shapes included a concavity at the top of the shape. Responses of both neurons can be well-explained by a two-dimensional angular position × boundary curvature model that captures the conformation of the shape boundary (Kim et al. 2019a). Panel adapted from Kim et al. (2019a) (CC BY 4.0). (<strong>b</strong>) Example of position-invariant shape tuning. This neuron shows strong narrow tuning for the orientation of a shape stimulus, responding best when the sharp convex projection is to the lower left. Shape selectivity was consistent irrespective of the absolute position of the shape within the receptive field (compare tuning for the different lines). The response magnitude varied across position, but the preference remained the same.
</font></p>
<h3 id="fig4-object-centered-tuning-for-boundary-conformation-in-v4" class="relative group">Fig4. Object-centered tuning for boundary conformation in V4 <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig4-object-centered-tuning-for-boundary-conformation-in-v4" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
      <img
        width="3601"
        height="1814"
        class="mx-auto my-0 rounded-md"
        alt="Fig4"
        loading="lazy" decoding="async"
        
          src="/publications/annurevvissci_2020/Fig4_hu_2da9e280963c81ef.gif"
          srcset="/publications/annurevvissci_2020/Fig4_hu_15796c2cca2c8217.gif 330w,/publications/annurevvissci_2020/Fig4_hu_2da9e280963c81ef.gif 660w
          
            ,/publications/annurevvissci_2020/Fig4_hu_cc4223ec88b5ece3.gif 1024w
          
          
            ,/publications/annurevvissci_2020/Fig4_hu_c7e783766d89a155.gif 1320w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
(<strong>a</strong>) Preference for a sharp convexity pointing up could be achieved by pooling signals from units tuned to an appropriate combination of orientations (feature template) and repeating the template at multiple positions [translation in the receptive field (RF)]. (<strong>b</strong>) This model would predict similar responses to the two shapes shown, one with a convex projection at the top of the shape and the other with a concave contour at the bottom of the shape, and would therefore not represent an object-centered code. (<strong>c</strong>) Example of object-centered tuning for contour conformation. Responses of this neuron show clear rotation tuning for a shape with a concave feature along the boundary. Responses are strongest (orange arrow) when the concavity is to the right of shape center. When the same boundary conformation forms a convex projection to the left of shape center, responses are weak (blue arrow). Thus, responses are not dictated by contour conformation alone.
</font></p>
<h3 id="fig5-representation-of-real-but-not-accidental-object-boundaries-in-v4" class="relative group">Fig5. Representation of real but not accidental object boundaries in V4 <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig5-representation-of-real-but-not-accidental-object-boundaries-in-v4" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
      <img
        width="3770"
        height="1402"
        class="mx-auto my-0 rounded-md"
        alt="Fig5"
        loading="lazy" decoding="async"
        
          src="/publications/annurevvissci_2020/Fig5_hu_107c29e092aed2f4.gif"
          srcset="/publications/annurevvissci_2020/Fig5_hu_814fd55a15211889.gif 330w,/publications/annurevvissci_2020/Fig5_hu_107c29e092aed2f4.gif 660w
          
            ,/publications/annurevvissci_2020/Fig5_hu_f102386bd2f7e0b0.gif 1024w
          
          
            ,/publications/annurevvissci_2020/Fig5_hu_2f25e500a44e68fd.gif 1320w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
(<strong>a, b</strong>) Accidental versus real contours. The angle Θ in panel a is a real contour, while in panel b, it is formed by the accidental occlusion of one circle by another. Accidental contours bound the occluded object, but they carry no information about its true shape, and they are perceptually discounted. (<strong>c</strong>) Responses of two example neurons that encode real but not accidental contours. We studied responses of neurons to crescent shapes in eight orientations (x axis), either in isolation (orange) or in combination with a circle (magenta); the circle was also presented in isolation (blue) at the same eight positions in the receptive field as in the combination stimulus. The neuron on the left responds preferentially to shapes with a sharp convexity at the bottom, as reflected in the tuning curve for the crescent alone (orange). When the crescent is formed by partial occlusion in the case of the combination stimulus, responses are suppressed (magenta) because the preferred sharp convexity is now an accidental feature. The neuron on the right responds best to shapes with a broad convexity to the upper right, consistent with the strong responses to the circle alone (blue). In this case, responses are not suppressed with the addition of a circle because the preferred broad convexity remains a real contour (for further details, see Bushnell et al. 2011b). (<strong>d</strong>) A population of V4 neurons can provide a complete representation of isolated shapes based on the component contour features. For example, the cat may be encoded by V4 neurons selective for sharp convexities to the upper right and upper left; concavity to the top; and broad convexities to the right, left, and bottom (see Pasupathy &amp; Connor 2002). Panels a–c adapted from Bushnell et al. (2011b) (CC BY-NC-SA 3.0).
</font></p>
<h3 id="fig6-joint-encoding-of-multiple-features-for-object-segmentation" class="relative group">Fig6. Joint encoding of multiple features for object segmentation <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig6-joint-encoding-of-multiple-features-for-object-segmentation" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
      <img
        width="3698"
        height="1788"
        class="mx-auto my-0 rounded-md"
        alt="Fig6"
        loading="lazy" decoding="async"
        
          src="/publications/annurevvissci_2020/Fig6_hu_42b5530de6c69660.gif"
          srcset="/publications/annurevvissci_2020/Fig6_hu_efd6f0a5abf0d8b.gif 330w,/publications/annurevvissci_2020/Fig6_hu_42b5530de6c69660.gif 660w
          
            ,/publications/annurevvissci_2020/Fig6_hu_4f1d70233886d98a.gif 1024w
          
          
            ,/publications/annurevvissci_2020/Fig6_hu_4d962524653d23f0.gif 1320w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
The input image on the left includes a variety of cues; the bottom images are filtered to include information from each cue in isolation and illustrate that form information may be encoded by a contrast in luminance, color, or texture. When viewing such a stimulus, responses of individual V4 neurons are dictated by tuning in a high-dimensional stimulus space defined by shape, luminance, color, texture, blur, depth, etc., which facilitates the effective segmentation of visual objects from the background that may be defined by contrast along a variety of stimulus dimensions.
</font></p>
<h3 id="fig7-goal-oriented-representations" class="relative group">Fig7. Goal-oriented representations <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig7-goal-oriented-representations" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
      <img
        width="3731"
        height="2029"
        class="mx-auto my-0 rounded-md"
        alt="Fig7"
        loading="lazy" decoding="async"
        
          src="/publications/annurevvissci_2020/Fig7_hu_790dd3a9f69c7384.gif"
          srcset="/publications/annurevvissci_2020/Fig7_hu_2f4dd9a75b1d3efa.gif 330w,/publications/annurevvissci_2020/Fig7_hu_790dd3a9f69c7384.gif 660w
          
            ,/publications/annurevvissci_2020/Fig7_hu_a373d79062c5a34.gif 1024w
          
          
            ,/publications/annurevvissci_2020/Fig7_hu_d982e83fbf7416d8.gif 1320w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
(<strong>a</strong>) When confronted with the challenge of spotting bananas in a cluttered produce aisle, the subject may saccade to different locations with yellow objects (dashed trajectory) and compare the shape of the object at the attentional focus (circles) with a remembered object. Area V4 is thought to be important for all aspects of this process. (<strong>b</strong>) Size illusion. The retinal sizes of the two sasquatches in this image are identical, but the perceived sizes are dramatically different. This is because the surrounding context suggests that the sasquatch at right is farther away from the observer; thus, the same retinal size would imply a much larger sasquatch farther away.
</font></p>
<h3 id="fig8-interactions-between-the-visual-and-frontal-cortex-during-shape-discrimination" class="relative group">Fig8. Interactions between the visual and frontal cortex during shape discrimination <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig8-interactions-between-the-visual-and-frontal-cortex-during-shape-discrimination" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
      <img
        width="3791"
        height="2102"
        class="mx-auto my-0 rounded-md"
        alt="Fig8"
        loading="lazy" decoding="async"
        
          src="/publications/annurevvissci_2020/Fig8_hu_3244b50f25e755b3.gif"
          srcset="/publications/annurevvissci_2020/Fig8_hu_29a0abf6748d3682.gif 330w,/publications/annurevvissci_2020/Fig8_hu_3244b50f25e755b3.gif 660w
          
            ,/publications/annurevvissci_2020/Fig8_hu_a2c3969685590d55.gif 1024w
          
          
            ,/publications/annurevvissci_2020/Fig8_hu_87f268fd992b5095.gif 1320w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
(<strong>a, b</strong>) Responses of two example V4 neurons that exhibit different response profiles to partially occluded shape stimuli. PSTHs in panel a exhibit two transient peaks (black and red bars), while those in panel b exhibit only one transient peak (black bar). During the first transient in both neurons, responses decline with increasing levels of occlusion (line colors; decreasing percent visible area). During the second transient in panel a, which may be based on feedback from frontal cortex, responses are stronger for intermediate levels of occlusion (for further details, see Fyall et al. 2017, Kosai et al. 2014). Adapted from Fyall et al. (2017) (CC-BY). (<strong>c, d</strong>) Psychometric and neurometric curves based on the data in panels a and b, respectively. In both, psychometric performance (dark gray dotted line) declines with increasing levels of occlusion. The neurometric curve based on a larger time window (orange line) shows improved performance at intermediate levels of occlusion for the neuron in panel a but not the one in panel b due to the enhanced shape selectivity for occluded stimuli during the second transient peak.
</font></p>
<h3 id="fig9-memory-encoding-in-v4" class="relative group">Fig9. Memory encoding in V4 <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig9-memory-encoding-in-v4" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
      <img
        width="2533"
        height="1650"
        class="mx-auto my-0 rounded-md"
        alt="Fig9"
        loading="lazy" decoding="async"
        
          src="/publications/annurevvissci_2020/Fig9_hu_ed95a8007b37d8c.gif"
          srcset="/publications/annurevvissci_2020/Fig9_hu_a30c537fa829c338.gif 330w,/publications/annurevvissci_2020/Fig9_hu_ed95a8007b37d8c.gif 660w
          
            ,/publications/annurevvissci_2020/Fig9_hu_56f5e03745afa280.gif 1024w
          
          
            ,/publications/annurevvissci_2020/Fig9_hu_d57f53aa61fe2ba9.gif 1320w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
Responses of an example neuron during the performance of a sequential shape-discrimination task are shown. Stimulus 1 was presented at central fixation (outside the receptive field of the neuron), followed by an inter-stimulus interval (ISI), and stimulus 2 was presented within the receptive field (RF). The animal had to report whether stimuli 1 and 2 were the same or different. Stimulus 1 and stimulus 2 could be shapes A or B, for a total of four conditions (for details, see Kosai et al. 2014). Responses of this neuron include three task-relevant pieces of information. First, the responses provide a sensory representation of stimulus 2 with stronger responses for shape A than shape B (compare the blue solid line and orange dashed line with the other two lines). Second, a memory representation of stimulus 1 is also evident during the ISI (blue arrow), with stronger responses when stimulus 1 was shape B (blue lines) rather than shape A (orange lines). Finally, responses also reflect whether stimuli 1 and 2 were the same or different with stronger responses during the presentation of stimulus 2 when stimuli 1 and 2 were different (solid lines, black arrows).
</font></p>

      </div>
    </section>
    <footer class="max-w-prose pt-8 print:hidden">
      

      

      
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="group flex" href="/publications/curropinneurobiol_2019/">
              <span
                class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
                ><span class="ltr:inline rtl:hidden">&larr;</span
                ><span class="ltr:hidden rtl:inline">&rarr;</span></span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Object shape and surface properties are jointly encoded in mid-level ventral visual cortex</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2019-10-01 00:00:00 &#43;0000 UTC">1 October 2019</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
            <a class="group flex text-right" href="/publications/jneurosci_2022/">
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Perceptual Texture Dimensions Modulate Neuronal Response Dynamics in Visual Cortical Area V4</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2022-01-26 00:00:00 &#43;0000 UTC">26 January 2022</time>
                  
                </span>
              </span>
              <span
                class="ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[-2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
                ><span class="ltr:inline rtl:hidden">&rarr;</span
                ><span class="ltr:hidden rtl:inline">&larr;</span></span
              >
            </a>
          
        </span>
      </div>
    </div>
  


      
        
          
        
      
    </footer>
  </article>

      </main>
      
        <div
          class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12"
          id="to-top"
          hidden="true"
        >
          <a
            href="#the-top"
            class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
            aria-label="Scroll to top"
            title="Scroll to top"
          >
            &uarr;
          </a>
        </div>
      <footer class="py-10 print:hidden">
  
  
  <div class="flex items-center justify-between">
    <div>
      
      
        <p class="text-sm text-neutral-500 dark:text-neutral-400">
            &copy;
            2025
            Taekjun Kim
        </p>
      
      
      
        <p class="text-xs text-neutral-500 dark:text-neutral-400">
          
          
          Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
            href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href="https://github.com/jpanther/congo" target="_blank" rel="noopener noreferrer">Congo</a>
        </p>
      
    </div>
    <div class="flex flex-row items-center">
      
      
      
      
    </div>
  </div>
  
  
</footer>
<div
  id="search-wrapper"
  class="invisible fixed inset-0 z-50 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="http://localhost:1313/"
>
  <div
    id="search-modal"
    class="top-20 mx-auto flex min-h-0 w-full max-w-3xl flex-col rounded-md border border-neutral-200 bg-neutral shadow-lg dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex flex-none items-center justify-between px-2">
      <form class="flex min-w-0 flex-auto items-center">
        <div class="flex h-8 w-8 items-center justify-center text-neutral-400">
          <span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span>
        </div>
        <input
          type="search"
          id="search-query"
          class="mx-1 flex h-12 flex-auto appearance-none bg-transparent focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex h-8 w-8 items-center justify-center text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>
</span>
      </button>
    </header>
    <section class="flex-auto overflow-auto px-2">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

    </div>
  </body>
</html>
