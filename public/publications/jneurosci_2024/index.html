






<!doctype html>
<html
  lang="en"
  dir="ltr"
  class="scroll-smooth"
  data-default-appearance="light"
  data-auto-appearance="true"
><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="#FFFFFF" />
  
  <title>Neural correlates of crowding in macaque area V4 &middot; Taekjun Kim</title>
    <meta name="title" content="Neural correlates of crowding in macaque area V4 &middot; Taekjun Kim" />
  
  
  
  
  
  <script
    type="text/javascript"
    src="/js/appearance.min.8a082f81b27f3cb2ee528df0b0bdc39787034cf2cc34d4669fbc9977c929023c.js"
    integrity="sha256-iggvgbJ/PLLuUo3wsL3Dl4cDTPLMNNRmn7yZd8kpAjw="
  ></script>
  
  
  
  
  
  
  
    
  
  
  <link
    type="text/css"
    rel="stylesheet"
    href="/css/main.bundle.min.bb20018254d048642b9bb4d07c490f792d638246be64872943e3fefe8ef7c064.css"
    integrity="sha256-uyABglTQSGQrm7TQfEkPeS1jgka&#43;ZIcpQ&#43;P&#43;/o73wGQ="
  />
  
    
    
    
  
  
  
    
    
  
  
  
  
    
    <script
      defer
      type="text/javascript"
      id="script-bundle"
      src="/js/main.bundle.min.af5d9722112bedac95702865c340bcd6286c4e9b2c15ce26b531ea1fba974cb8.js"
      integrity="sha256-r12XIhEr7ayVcChlw0C81ihsTpssFc4mtTHqH7qXTLg="
      data-copy="Copy"
      data-copied="Copied"
    ></script>
  
  
  <meta
    name="description"
    content="
      
        Taekjun Kim, Anitha Pasupathy Journal of Neuroscience
      
    "
  />
  
  
  
  <link rel="canonical" href="http://localhost:1313/publications/jneurosci_2024/" />
  
  
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
    <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  
  <meta property="og:url" content="http://localhost:1313/publications/jneurosci_2024/">
  <meta property="og:site_name" content="Taekjun Kim">
  <meta property="og:title" content="Neural correlates of crowding in macaque area V4">
  <meta property="og:description" content="Taekjun Kim, Anitha Pasupathy Journal of Neuroscience">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="publications">
    <meta property="article:published_time" content="2024-06-12T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-06-12T00:00:00+00:00">
    <meta property="article:tag" content="Primate">
    <meta property="article:tag" content="Crowding">
    <meta property="article:tag" content="Electrophysiology">
    <meta property="article:tag" content="Area V4">
    <meta property="article:tag" content="Vision">
    <meta property="article:tag" content="Neuroscience">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Neural correlates of crowding in macaque area V4">
  <meta name="twitter:description" content="Taekjun Kim, Anitha Pasupathy Journal of Neuroscience">

  
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Selected publications",
    "name": "Neural correlates of crowding in macaque area V4",
    "headline": "Neural correlates of crowding in macaque area V4",
    
    "abstract": "Taekjun Kim, Anitha Pasupathy \u003ccode\u003eJournal of Neuroscience\u003c\/code\u003e",
    "inLanguage": "en",
    "url" : "http:\/\/localhost:1313\/publications\/jneurosci_2024\/",
    "author" : {
      "@type": "Person",
      "name": "Taekjun Kim"
    },
    "copyrightYear": "2024",
    "dateCreated": "2024-06-12T00:00:00\u002b00:00",
    "datePublished": "2024-06-12T00:00:00\u002b00:00",
    
    "dateModified": "2024-06-12T00:00:00\u002b00:00",
    
    "keywords": ["Primate","Crowding","Electrophysiology","area V4","Vision","Neuroscience"],
    
    "mainEntityOfPage": "true",
    "wordCount": "1976"
  }
  </script>
    
    <script type="application/ld+json">
    {
   "@context": "https://schema.org",
   "@type": "BreadcrumbList",
   "itemListElement": [
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/",
       "name": "",
       "position": 1
     },
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/publications/",
       "name": "Selected Publications",
       "position": 2
     },
     {
       "@type": "ListItem",
       "name": "Neural Correlates of Crowding in Macaque Area V4",
       "position": 3
     }
   ]
 }
  </script>

  
  <meta name="author" content="Taekjun Kim" />
  
    
      <link href="mailto:taekjunkim1223@gmail.com" rel="me" />
    
      <link href="https://github.com/taekjunkim" rel="me" />
    
      <link href="https://linkedin.com/in/taekjun-kim" rel="me" />
    
      <link href="https://scholar.google.com/citations?user=pP442rIAAAAJ&amp;hl=en" rel="me" />
    
  
  
  






  
  

  
  

</head>
<body
    class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"
  >
    <div id="the-top" class="absolute flex self-center">
      <a
        class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600"
        href="#main-content"
        ><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span
        >Skip to main content</a
      >
    </div>
    
    
      <header class="py-6 font-semibold text-neutral-900 dark:text-neutral sm:py-10 print:hidden">
  <nav class="flex items-start justify-between sm:items-center">
    
    <div class="flex flex-row items-center">
      
  <a
    class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
    rel="me"
    href="/"
    >Taekjun Kim</a
  >

    </div>
    
    
      <ul class="flex list-none flex-col text-end sm:flex-row">
        
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/about/"
                  title=""
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >About Me</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/posts/"
                  title="Posts"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Posts</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/publications/"
                  title="Selected publications"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Publications</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/tags/"
                  title="Tags"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Tags</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                
                
                  <button
                    id="search-button-1"
                    title="Search (/)"
                  >
                    
                      <span
                        class="group-dark:hover:text-primary-400 transition-colors group-hover:text-primary-600"
                      ><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></span><span
                        class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                        ></span
                      >
                    
                  </button>
                
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                
                <button
                  id="appearance-switcher-1"
                  type="button"
                  aria-label="appearance switcher"
                >
                  <span
                    class="group-dark:hover:text-primary-400 inline transition-colors group-hover:text-primary-600 dark:hidden"
                    title="Switch to dark appearance"
                  >
                    <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>
</span><span
                        class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                        ></span
                      >
                    
                  </span>
                  <span
                    class="group-dark:hover:text-primary-400 hidden transition-colors group-hover:text-primary-600 dark:inline"
                    title="Switch to light appearance"
                  >
                    
                      <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>
</span>
                    
                    
                      <span
                        class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                        ></span
                      >
                    
                  </span>
                </button>
              
            </li>
          
            
              
          
        
      </ul>
    
  </nav>
</header>

    
    <div class="relative flex grow flex-col">
      <main id="main-content" class="grow">
        
  <article>
    <header class="max-w-prose">
      
        <ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden">
  
  
    
  
    
  
  <li class="hidden inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="/"
      ></a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class=" inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="/publications/"
      >Selected publications</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="hidden inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="/publications/jneurosci_2024/"
      >Neural correlates of crowding in macaque area V4</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

</ol>


      
      <h1 class="mb-8 mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
        Neural correlates of crowding in macaque area V4
      </h1>
      
        <div class="mb-10 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
          





  
  



  

  
  
    
  

  

  

  
    
  

  


  <div class="flex flex-row flex-wrap items-center">
    
    
      <time datetime="2024-06-12 00:00:00 &#43;0000 UTC">12 June 2024</time><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">10 mins</span>
    

    
    
  </div>

  
  
    <div class="my-1 flex flex-wrap text-xs leading-relaxed text-neutral-500 dark:text-neutral-400">
      
        
      
        
          
            <a
              href="/tags/primate/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Primate</a
            >
          
            <a
              href="/tags/crowding/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Crowding</a
            >
          
            <a
              href="/tags/electrophysiology/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Electrophysiology</a
            >
          
            <a
              href="/tags/area-v4/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Area V4</a
            >
          
            <a
              href="/tags/vision/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Vision</a
            >
          
            <a
              href="/tags/neuroscience/"
              class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400"
              >Neuroscience</a
            >
          
        
      
    </div>
  


        </div>
      
      
    </header>
    <section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row">
      
        <div class="order-first px-0 lg:order-last lg:max-w-xs lg:ps-8">
          <div class="toc pe-5 lg:sticky lg:top-10 print:hidden">
            <details open class="-ms-5 mt-0 overflow-hidden rounded-lg ps-5">
  <summary
    class="block cursor-pointer bg-neutral-100 py-1 ps-5 text-lg font-semibold text-neutral-800 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden"
  >
    Table of Contents
  </summary>
  <div class="border-s border-dotted border-neutral-300 py-2 ps-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#article-info">Article info</a></li>
    <li><a href="#abstract">Abstract</a></li>
    <li><a href="#figures">Figures</a>
      <ul>
        <li><a href="#fig1-visual-stimulus-design">Fig1. Visual stimulus design</a></li>
        <li><a href="#fig2-effect-of-targetdistractor-distance-on-shape-tuning">Fig2. Effect of target–distractor distance on shape tuning</a></li>
        <li><a href="#fig3-effect-of-distractor-number-on-responses-and-selectivity">Fig3. Effect of distractor number on responses and selectivity</a></li>
        <li><a href="#fig4-effects-of-distractor-position-on-visual-crowding-anisotropic-crowding-zone">Fig4. Effects of distractor position on visual crowding: anisotropic crowding zone</a></li>
        <li><a href="#fig5-effects-of-target-saliency-color-cue-on-visual-crowding">Fig5. Effects of target saliency (color cue) on visual crowding</a></li>
        <li><a href="#fig6-effects-of-target-saliency-shape-size-cues-on-visual-crowding">Fig6. Effects of target saliency (shape, size cues) on visual crowding</a></li>
        <li><a href="#fig7-test-of-texture-statistics-model">Fig7. Test of texture statistics model</a></li>
        <li><a href="#fig8-temporal-dynamics-of-population-decoding">Fig8. Temporal dynamics of population decoding</a></li>
        <li><a href="#fig9-hierarchical-saliency-computation-model">Fig9. Hierarchical saliency computation model</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</details>

          </div>
        </div>
      
      <div class="min-h-0 min-w-0 max-w-prose grow">
        <h2 id="article-info" class="relative group">Article info <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#article-info" aria-label="Anchor">#</a></span></h2><table>
  <thead>
      <tr>
          <th></th>
          <th></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><code>Authors</code></td>
          <td>Taekjun Kim, Anitha Pasupathy</td>
      </tr>
      <tr>
          <td><code>Publication date</code></td>
          <td>2024/06/12</td>
      </tr>
      <tr>
          <td><code>Journal</code></td>
          <td>Journal of Neuroscience</td>
      </tr>
      <tr>
          <td><code>DOI</code></td>
          <td><a href="https://doi.org/10.1523/JNEUROSCI.2260-23.2024" target="_blank" rel="noreferrer">https://doi.org/10.1523/JNEUROSCI.2260-23.2024</a></td>
      </tr>
  </tbody>
</table>
<h2 id="abstract" class="relative group">Abstract <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#abstract" aria-label="Anchor">#</a></span></h2><p>Visual crowding refers to the phenomenon where a target object that is easily identifiable in isolation becomes difficult to recognize when surrounded by other stimuli (distractors). Many psychophysical studies have investigated this phenomenon and proposed alternative models for the underlying mechanisms. One prominent hypothesis, albeit with mixed psychophysical support, posits that crowding arises from the loss of information due to pooled encoding of features from target and distractor stimuli in the early stages of cortical visual processing. However, neurophysiological studies have not rigorously tested this hypothesis. We studied the responses of single neurons in macaque (one male, one female) area V4, an intermediate stage of the object-processing pathway, to parametrically designed crowded displays and texture statistics-matched metameric counterparts. Our investigations reveal striking parallels between how crowding parameters—number, distance, and position of distractors—influence human psychophysical performance and V4 shape selectivity. Importantly, we also found that enhancing the salience of a target stimulus could alleviate crowding effects in highly cluttered scenes, and this could be temporally protracted reflecting a dynamical process. Thus, a pooled encoding of nearby stimuli cannot explain the observed responses, and we propose an alternative model where V4 neurons preferentially encode salient stimuli in crowded displays. Overall, we conclude that the magnitude of crowding effects is determined not just by the number of distractors and target–distractor separation but also by the relative salience of targets versus distractors based on their feature attributes—the similarity of distractors and the contrast between target and distractor stimuli.</p>
<h2 id="figures" class="relative group">Figures <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#figures" aria-label="Anchor">#</a></span></h2><h3 id="fig1-visual-stimulus-design" class="relative group">Fig1. Visual stimulus design <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig1-visual-stimulus-design" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
        <source
          
            srcset="/publications/jneurosci_2024/F1.large_hu_95e5f3254ef58ae4.webp 330w,/publications/jneurosci_2024/F1.large_hu_28c64be36984e83b.webp 660w
            
              ,/publications/jneurosci_2024/F1.large_hu_2b90892a7b17e3fb.webp 1024w
            
            
              
                ,/publications/jneurosci_2024/F1.large_hu_b859b7c1cb20d1aa.webp 1280w
              
            "
          
          sizes="100vw"
          type="image/webp"
        />
      
      <img
        width="1280"
        height="907"
        class="mx-auto my-0 rounded-md"
        alt="Fig1"
        loading="lazy" decoding="async"
        
          src="/publications/jneurosci_2024/F1.large_hu_260353cdf9909fbd.jpg"
          srcset="/publications/jneurosci_2024/F1.large_hu_91d02f02c1974ffd.jpg 330w,/publications/jneurosci_2024/F1.large_hu_260353cdf9909fbd.jpg 660w
          
            ,/publications/jneurosci_2024/F1.large_hu_2d89029eca3d5004.jpg 1024w
          
          
            ,/publications/jneurosci_2024/F1.large.jpg 1280w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
<strong>A</strong>, Tabulation of clutter conditions. For each target–distractor configuration (rows), responses to eight target rotations (# Conditions = 8) were evaluated, except when distractors were presented without a target (Target = None). An open circle under Metamer column indicates that metameric stimuli were also presented (see Materials and Methods).
<strong>B</strong>, Shape stimulus set. Target (red box) and distractor shapes were chosen from a set of 2D shapes [a subset of shapes created by Pasupathy and Connor (2001)]. Target stimulus was at the RF center, scaled to half of the estimated RF diameter.
<strong>C</strong>, The target stimulus was presented either (i) alone or in combination with various distractor arrangements which varied in terms of (ii) distance from central target, (iii) number, (iv) saliency defined by target color, and (v) shape, shape + size of distractors. In all conditions, the target shape was shown at eight rotations in 45° increments (as in i). Targets were achromatic or chromatic when presented alone. In all clutter conditions targets were achromatic except when target saliency was titrated by color (iv). Distractors were always achromatic. The target size was the same in all conditions, but it is scaled down in ii for illustration purposes. Distractors were the same size as target except when titrating saliency by size (yellow dot). Metameric stimulus pairs with matched texture statistics (in vi: panels 1–2, 3–4, and 5–6) were included to test the texture-pooling model (see Materials and Methods). Colored dots in A and C identify identical stimulus conditions repeated in the figure for illustration purposes.
</font></p>
<h3 id="fig2-effect-of-targetdistractor-distance-on-shape-tuning" class="relative group">Fig2. Effect of target–distractor distance on shape tuning <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig2-effect-of-targetdistractor-distance-on-shape-tuning" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
        <source
          
            srcset="/publications/jneurosci_2024/F2.large_hu_5c12ab8dc3a70ab1.webp 330w,/publications/jneurosci_2024/F2.large_hu_5ebc066671b36bc5.webp 660w
            
              
                ,/publications/jneurosci_2024/F2.large_hu_cef2bfbdc18c5e67.webp 1009w
              
            
            
              
                ,/publications/jneurosci_2024/F2.large_hu_cef2bfbdc18c5e67.webp 1009w
              
            "
          
          sizes="100vw"
          type="image/webp"
        />
      
      <img
        width="1009"
        height="1280"
        class="mx-auto my-0 rounded-md"
        alt="Fig2"
        loading="lazy" decoding="async"
        
          src="/publications/jneurosci_2024/F2.large_hu_244be7434faa65c4.jpg"
          srcset="/publications/jneurosci_2024/F2.large_hu_d980d25fb12cd956.jpg 330w,/publications/jneurosci_2024/F2.large_hu_244be7434faa65c4.jpg 660w
          
            ,/publications/jneurosci_2024/F2.large.jpg 1009w
          
          
            ,/publications/jneurosci_2024/F2.large.jpg 1009w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
<strong>A–C</strong>, Example neuron.
<strong>A</strong>, Raster plots and PSTHs for responses to (rows) target alone, target + far, middle, and near distractor conditions, respectively. Columns show responses to different target orientations, rank-ordered by responses to target-alone. Stimulus panels are shown here at a higher contrast to aid visibility (see Fig. 1C for veridical illustration).
<strong>B</strong>, Tuning curves based on average responses (0–400 ms) for the four target + distractor conditions. Error bars indicate the standard error of the mean.
<strong>C</strong>, Average PSTHs for the preferred (top 4) and nonpreferred (bottom 4) targets for each distractor condition are shown in solid and dotted lines, respectively. Black asterisks indicate time points with significant difference between solid and dotted curves (Mann–Whitney U test in a 30 ms sliding window; p &lt; 0.05). <strong>D–F</strong>, Population results.
<strong>D</strong>, Average normalized tuning curves across the subpopulation of neurons with significant shape selectivity in the target alone condition (73/147). Error bars indicate the standard error of the mean.
<strong>E</strong>, The distribution of distractor modulation index (DMI) for each distractor condition is presented. Filled bars represent neurons whose shape tuning curve exhibited statistically significant correlations with that in the “target alone” condition. Red symbols denote the mean correlation values in neurons within the lower (0–50%), middle (25–75%), and upper (50–100%) ranges of the DMI distribution.
<strong>F</strong>, The proportion of neurons with significant shape-dependent modulation (i.e., asterisks in C) as a function of time for each distractor condition. The red shaded area, representing the equivalent analysis for the “target alone” condition, is included for panel-to-panel comparison.
</font></p>
<h3 id="fig3-effect-of-distractor-number-on-responses-and-selectivity" class="relative group">Fig3. Effect of distractor number on responses and selectivity <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig3-effect-of-distractor-number-on-responses-and-selectivity" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
        <source
          
            srcset="/publications/jneurosci_2024/F3.large_hu_4f5673c6b834a8a6.webp 330w,/publications/jneurosci_2024/F3.large_hu_6ecdd4c998ae614e.webp 660w
            
              
                ,/publications/jneurosci_2024/F3.large_hu_a83cd4f36d2c758a.webp 1016w
              
            
            
              
                ,/publications/jneurosci_2024/F3.large_hu_a83cd4f36d2c758a.webp 1016w
              
            "
          
          sizes="100vw"
          type="image/webp"
        />
      
      <img
        width="1016"
        height="1280"
        class="mx-auto my-0 rounded-md"
        alt="Fig3"
        loading="lazy" decoding="async"
        
          src="/publications/jneurosci_2024/F3.large_hu_6540ecfce017e9bf.jpg"
          srcset="/publications/jneurosci_2024/F3.large_hu_3e007a3f3ec2650b.jpg 330w,/publications/jneurosci_2024/F3.large_hu_6540ecfce017e9bf.jpg 660w
          
            ,/publications/jneurosci_2024/F3.large.jpg 1016w
          
          
            ,/publications/jneurosci_2024/F3.large.jpg 1016w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
<strong>A–C</strong>, Example neuron responses.
<strong>A</strong>, Raster plots with PSTHs for responses to (rows) target alone, target + 1, 3, or 6 distractors, respectively. Columns show responses to different target orientations.
<strong>B</strong>, Target shape selectivity curves of the example unit for the four different conditions.
<strong>C</strong>, Average PSTHs for the preferred (top 4) and nonpreferred (bottom 4) targets.
<strong>D–F</strong>, Population results.
<strong>D</strong>, Average normalized tuning curves for target shape selectivity in the presence and absence of distractors.
<strong>E</strong>, The distribution of distractor modulation index (DMI) for each distractor condition is presented. Filled bars represent neurons whose shape tuning curve exhibited statistically significant correlations with that in the “target alone” condition. Red symbols denote the mean correlation values in neurons within the lower (0–50%), middle (25–75%), and upper (50–100%) ranges of the DMI distribution.
<strong>F</strong>, The proportion of neurons with significant shape-dependent modulation (i.e., asterisks in C) as a function of time for each distractor condition. All conventions are as in Figure 2.
</font></p>
<h3 id="fig4-effects-of-distractor-position-on-visual-crowding-anisotropic-crowding-zone" class="relative group">Fig4. Effects of distractor position on visual crowding: anisotropic crowding zone <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig4-effects-of-distractor-position-on-visual-crowding-anisotropic-crowding-zone" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
        <source
          
            srcset="/publications/jneurosci_2024/F4.large_hu_6858a8ac61eca209.webp 330w,/publications/jneurosci_2024/F4.large_hu_8b0bf01d6d35aea.webp 660w
            
              
                ,/publications/jneurosci_2024/F4.large_hu_bf145fc8a52e1030.webp 901w
              
            
            
              
                ,/publications/jneurosci_2024/F4.large_hu_bf145fc8a52e1030.webp 901w
              
            "
          
          sizes="100vw"
          type="image/webp"
        />
      
      <img
        width="901"
        height="1280"
        class="mx-auto my-0 rounded-md"
        alt="Fig4"
        loading="lazy" decoding="async"
        
          src="/publications/jneurosci_2024/F4.large_hu_bfa07dc3feecff24.jpg"
          srcset="/publications/jneurosci_2024/F4.large_hu_43ce926fa1964014.jpg 330w,/publications/jneurosci_2024/F4.large_hu_bfa07dc3feecff24.jpg 660w
          
            ,/publications/jneurosci_2024/F4.large.jpg 901w
          
          
            ,/publications/jneurosci_2024/F4.large.jpg 901w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
<strong>A, B</strong>, RF summary illustrates both location (<strong>A</strong>) and size (<strong>B</strong>). RFs from two monkeys are positioned in the lower right visual field and their sizes increase with eccentricity. Red line in B denotes the values computed using the equation employed to estimate the RF diameter (see Materials and Methods).
<strong>C</strong>, For each neuron, the positions of the distractors were transformed into a radial/tangential axis relative to the fixation point. The yellow circles depict two example RF locations. The red, green, and blue arrows indicate the radial outward, radial inward, and tangential directions with respect to the target location.
<strong>D</strong>, The histograms illustrate the correlation between tuning curves for target alone versus target + one distractor calculated at 12 distractor positions, which were realigned based on the radial and tangential axes originating from the fixation point. Filled bars indicate statistically significant cases. In the polar plot, red and black data points compare the median values (red vertical lines) and proportion of significant cases (filled bars) from histograms of the matched directions, respectively.
<strong>E</strong>, RF shape estimation from four example neurons. A 2D Gaussian fit (white ellipses) is superimposed on the raw response map (7 × 7 grid, 1° intervals). Theta angle represents the counterclockwise angle of the major axis of RF with respect to the horizontal line. Red and blue dots indicate Gaussian fit center and RF hotspot, respectively.
<strong>F</strong>, Distribution of the major axis orientation in the Gaussian RF fitting of the recorded neurons. Red vertical line indicates the median value. For the RFs in the lower right visual field, an angle bigger than 90° represents an elongated RF shape oriented toward the fixation point.
<strong>G</strong>, In most neurons, the RF hotspot (y-axis) is closer to the fixation point than the center of the 2D Gaussian fit (Wilcoxon signed-rank test; p &lt; 0.05), suggesting that the RF extent is larger in the outward radial direction compared with the inward direction. The red line represents the unity line.
</font></p>
<h3 id="fig5-effects-of-target-saliency-color-cue-on-visual-crowding" class="relative group">Fig5. Effects of target saliency (color cue) on visual crowding <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig5-effects-of-target-saliency-color-cue-on-visual-crowding" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
        <source
          
            srcset="/publications/jneurosci_2024/F5.large_hu_52d0e453584eeff0.webp 330w,/publications/jneurosci_2024/F5.large_hu_e4f4dc560f9527aa.webp 660w
            
              
                ,/publications/jneurosci_2024/F5.large_hu_8c43169213c98b31.webp 1012w
              
            
            
              
                ,/publications/jneurosci_2024/F5.large_hu_8c43169213c98b31.webp 1012w
              
            "
          
          sizes="100vw"
          type="image/webp"
        />
      
      <img
        width="1012"
        height="1280"
        class="mx-auto my-0 rounded-md"
        alt="Fig5"
        loading="lazy" decoding="async"
        
          src="/publications/jneurosci_2024/F5.large_hu_f3c02aeeddb8a203.jpg"
          srcset="/publications/jneurosci_2024/F5.large_hu_ade7cb2e851f61a4.jpg 330w,/publications/jneurosci_2024/F5.large_hu_f3c02aeeddb8a203.jpg 660w
          
            ,/publications/jneurosci_2024/F5.large.jpg 1012w
          
          
            ,/publications/jneurosci_2024/F5.large.jpg 1012w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
Target (gray or colored) appeared alone or in combination with six random distractors.
<strong>A–C</strong>, Example unit responses.
<strong>A</strong>, Raster plots with PSTHs.
<strong>B</strong>, Target shape selectivity curves of the example unit for the four different conditions.
<strong>C</strong>, Average PSTHs for the preferred (top 4) and nonpreferred (bottom 4) targets.
<strong>D–F</strong>, Population results.
<strong>D</strong>, Average normalized tuning curves for target shape selectivity across conditions.
<strong>E</strong>, The distribution of distractor modulation index (DMI) for each distractor condition. Filled bars represent neurons whose shape tuning curve exhibited statistically significant correlation with that in the “target alone” condition. Red symbols denote the mean correlation values for neurons within the lower (0–50%), middle (25–75%), and upper (50–100%) ranges of the DMI distribution.
<strong>F</strong>, The proportion of neurons with significant shape-dependent modulation as a function of time for each distractor condition. All conventions are as in Figure 2.
</font></p>
<h3 id="fig6-effects-of-target-saliency-shape-size-cues-on-visual-crowding" class="relative group">Fig6. Effects of target saliency (shape, size cues) on visual crowding <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig6-effects-of-target-saliency-shape-size-cues-on-visual-crowding" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
        <source
          
            srcset="/publications/jneurosci_2024/F6.large_hu_783722682f7b32df.webp 330w,/publications/jneurosci_2024/F6.large_hu_f0b38921681bf6e3.webp 660w
            
              
                ,/publications/jneurosci_2024/F6.large_hu_7a1ea9f2b4e8301a.webp 1023w
              
            
            
              
                ,/publications/jneurosci_2024/F6.large_hu_7a1ea9f2b4e8301a.webp 1023w
              
            "
          
          sizes="100vw"
          type="image/webp"
        />
      
      <img
        width="1023"
        height="1280"
        class="mx-auto my-0 rounded-md"
        alt="Fig6"
        loading="lazy" decoding="async"
        
          src="/publications/jneurosci_2024/F6.large_hu_a87b85d3ce9613e.jpg"
          srcset="/publications/jneurosci_2024/F6.large_hu_e83303883bb4a55f.jpg 330w,/publications/jneurosci_2024/F6.large_hu_a87b85d3ce9613e.jpg 660w
          
            ,/publications/jneurosci_2024/F6.large.jpg 1023w
          
          
            ,/publications/jneurosci_2024/F6.large.jpg 1023w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
Target appeared alone or in combination with 12 small circles, six circles, or six random distractors.
<strong>A–C</strong>, Example unit responses.
<strong>A</strong>, Raster plots with PSTHs.
<strong>B</strong>, Target shape selectivity curves of the example unit from four different conditions.
<strong>C</strong>, Average PSTHs for the preferred (top 4) and nonpreferred (bottom 4) targets.
<strong>D–F</strong>, Population results.
<strong>D</strong>, Average normalized tuning curves for target shape selectivity across conditions.
<strong>E</strong>, The distribution of distractor modulation index (DMI) for each distractor condition. Filled bars represent neurons whose shape tuning curve exhibited statistically significant correlation with that in the “target alone” condition. Red symbols denote the mean correlation values for neurons within the lower (0–50%), middle (25–75%), and upper (50–100%) ranges of the DMI distribution.
<strong>F</strong>, The proportion of neurons with significant shape-dependent modulation as a function of time for each distractor condition. All conventions are as in Figure 2.
</font></p>
<h3 id="fig7-test-of-texture-statistics-model" class="relative group">Fig7. Test of texture statistics model <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig7-test-of-texture-statistics-model" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
        <source
          
            srcset="/publications/jneurosci_2024/F7.large_hu_29ea778e2b5859.webp 330w,/publications/jneurosci_2024/F7.large_hu_e1756cc930d657bd.webp 660w
            
              ,/publications/jneurosci_2024/F7.large_hu_b5dcc62d15247d41.webp 1024w
            
            
              
                ,/publications/jneurosci_2024/F7.large_hu_6a1388154462c10a.webp 1280w
              
            "
          
          sizes="100vw"
          type="image/webp"
        />
      
      <img
        width="1280"
        height="299"
        class="mx-auto my-0 rounded-md"
        alt="Fig7"
        loading="lazy" decoding="async"
        
          src="/publications/jneurosci_2024/F7.large_hu_edd4836402cfa3ba.jpg"
          srcset="/publications/jneurosci_2024/F7.large_hu_b7cf2331cd3f3afb.jpg 330w,/publications/jneurosci_2024/F7.large_hu_edd4836402cfa3ba.jpg 660w
          
            ,/publications/jneurosci_2024/F7.large_hu_36b59419f9e8baa5.jpg 1024w
          
          
            ,/publications/jneurosci_2024/F7.large.jpg 1280w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
<strong>A–C</strong>, Test of the texture statistics model for visual crowding.
<strong>A</strong>, For each neuron, we computed two correlations: (1) the correlation between responses to “target + random distractor” and “target alone” stimuli and (2) the correlation between responses to “target + random distractor” stimuli and matched metamers. Population data are shifted below the diagonal suggesting that responses to target + random distractors are better correlated with the “target alone” condition (x-axis). Cells with a significant correlation (p &lt; 0.05) in x-axis alone, y-axis alone, or both are identified (see legend).
<strong>B, C</strong>, The same analyses as in A for the “circle distractor” (<strong>B</strong>) and “small circle distractor” (<strong>C</strong>) conditions in which the target is more salient.
</font></p>
<h3 id="fig8-temporal-dynamics-of-population-decoding" class="relative group">Fig8. Temporal dynamics of population decoding <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig8-temporal-dynamics-of-population-decoding" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
        <source
          
            srcset="/publications/jneurosci_2024/F8.large_hu_92e08275cf48dbbd.webp 330w,/publications/jneurosci_2024/F8.large_hu_84a48c6184739901.webp 660w
            
              ,/publications/jneurosci_2024/F8.large_hu_604bfdb20fa28a15.webp 1024w
            
            
              
                ,/publications/jneurosci_2024/F8.large_hu_80735377297ecf3a.webp 1280w
              
            "
          
          sizes="100vw"
          type="image/webp"
        />
      
      <img
        width="1280"
        height="788"
        class="mx-auto my-0 rounded-md"
        alt="Fig8"
        loading="lazy" decoding="async"
        
          src="/publications/jneurosci_2024/F8.large_hu_adf151e992c4ed6d.jpg"
          srcset="/publications/jneurosci_2024/F8.large_hu_90cd8a846cb1ce02.jpg 330w,/publications/jneurosci_2024/F8.large_hu_adf151e992c4ed6d.jpg 660w
          
            ,/publications/jneurosci_2024/F8.large_hu_ac1121fbbc79fdb0.jpg 1024w
          
          
            ,/publications/jneurosci_2024/F8.large.jpg 1280w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
Population decoding performance plotted as a function of time across different distractor conditions. In all four panels, target alone (red) and target + 6 near distractors (black) are identical. Decoding performance declines in the presence of distractors but time course varies across conditions. For the salient target conditions (light blue curve in <strong>C</strong>, gray curves in <strong>D</strong>), rise time and the maximum decoding performance time are delayed compared with target alone conditions (red and blue curves in <strong>C,D</strong>), but this is not the case for distance and number effects (gray curves in <strong>A,B</strong>). Green line indicates the chance level of target orientation decoding (0.125, 1 out of 8). Different colored lines represent different target–distractor configurations.
</font></p>
<h3 id="fig9-hierarchical-saliency-computation-model" class="relative group">Fig9. Hierarchical saliency computation model <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#fig9-hierarchical-saliency-computation-model" aria-label="Anchor">#</a></span></h3><p>





<figure>
    
    








  
    <picture
      class="mx-auto my-0 rounded-md"
      
    >
      
      
      
      
        <source
          
            srcset="/publications/jneurosci_2024/F9.large_hu_60ad7e30ddb1c4d.webp 330w,/publications/jneurosci_2024/F9.large_hu_ad9f05266795f968.webp 660w
            
              ,/publications/jneurosci_2024/F9.large_hu_5c022797f0d3a0fe.webp 1024w
            
            
              
                ,/publications/jneurosci_2024/F9.large_hu_4576544ee860e26e.webp 1280w
              
            "
          
          sizes="100vw"
          type="image/webp"
        />
      
      <img
        width="1280"
        height="680"
        class="mx-auto my-0 rounded-md"
        alt="Fig9"
        loading="lazy" decoding="async"
        
          src="/publications/jneurosci_2024/F9.large_hu_772a4d45f29e58d7.jpg"
          srcset="/publications/jneurosci_2024/F9.large_hu_a1a100d7eede746e.jpg 330w,/publications/jneurosci_2024/F9.large_hu_772a4d45f29e58d7.jpg 660w
          
            ,/publications/jneurosci_2024/F9.large_hu_fa6ce806426e7268.jpg 1024w
          
          
            ,/publications/jneurosci_2024/F9.large.jpg 1280w
          "
          sizes="100vw"
        
      />
    </picture>
  


</figure>

<font size="2">
Visual input is first processed in parallel by a set of low-level feature detectors (e.g., orientation, color, luminance, texture) in earlier visual areas. To focus on the central region of the visual scene, visual inputs (112 × 112 pixels) and feature maps (28 × 28 pixels) were cropped from the larger images of size 224 × 224 pixels and 55 × 55 pixels, respectively. Feature maps show the outputs from the first five filters from AlexNet. The next stage of processing performs a RF center-surround operation for each feature dimension and selectively combines only informative feature maps in which the RF center region is more strongly activated than its surround (see more details in the main text).
</font></p>

      </div>
    </section>
    <footer class="max-w-prose pt-8 print:hidden">
      

      

      
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="group flex" href="/publications/currbio_2023/">
              <span
                class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
                ><span class="ltr:inline rtl:hidden">&larr;</span
                ><span class="ltr:hidden rtl:inline">&rarr;</span></span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Dissociation in neuronal encoding of object versus surface motion in the primate brain</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2023-02-03 00:00:00 &#43;0000 UTC">3 February 2023</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
        </span>
      </div>
    </div>
  


      
        
          
        
      
    </footer>
  </article>

      </main>
      
        <div
          class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12"
          id="to-top"
          hidden="true"
        >
          <a
            href="#the-top"
            class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
            aria-label="Scroll to top"
            title="Scroll to top"
          >
            &uarr;
          </a>
        </div>
      <footer class="py-10 print:hidden">
  
  
  <div class="flex items-center justify-between">
    <div>
      
      
        <p class="text-sm text-neutral-500 dark:text-neutral-400">
            &copy;
            2025
            Taekjun Kim
        </p>
      
      
      
        <p class="text-xs text-neutral-500 dark:text-neutral-400">
          
          
          Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
            href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href="https://github.com/jpanther/congo" target="_blank" rel="noopener noreferrer">Congo</a>
        </p>
      
    </div>
    <div class="flex flex-row items-center">
      
      
      
      
    </div>
  </div>
  
  
</footer>
<div
  id="search-wrapper"
  class="invisible fixed inset-0 z-50 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="http://localhost:1313/"
>
  <div
    id="search-modal"
    class="top-20 mx-auto flex min-h-0 w-full max-w-3xl flex-col rounded-md border border-neutral-200 bg-neutral shadow-lg dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex flex-none items-center justify-between px-2">
      <form class="flex min-w-0 flex-auto items-center">
        <div class="flex h-8 w-8 items-center justify-center text-neutral-400">
          <span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span>
        </div>
        <input
          type="search"
          id="search-query"
          class="mx-1 flex h-12 flex-auto appearance-none bg-transparent focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex h-8 w-8 items-center justify-center text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>
</span>
      </button>
    </header>
    <section class="flex-auto overflow-auto px-2">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

    </div>
  </body>
</html>
