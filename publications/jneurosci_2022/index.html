<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="#FFFFFF"><title>Perceptual Texture Dimensions Modulate Neuronal Response Dynamics in Visual Cortical Area V4 &#183; Taekjun Kim</title>
<meta name=title content="Perceptual Texture Dimensions Modulate Neuronal Response Dynamics in Visual Cortical Area V4 &#183; Taekjun Kim"><script type=text/javascript src=/js/appearance.min.8a082f81b27f3cb2ee528df0b0bdc39787034cf2cc34d4669fbc9977c929023c.js integrity="sha256-iggvgbJ/PLLuUo3wsL3Dl4cDTPLMNNRmn7yZd8kpAjw="></script><link type=text/css rel=stylesheet href=/css/main.bundle.min.bb20018254d048642b9bb4d07c490f792d638246be64872943e3fefe8ef7c064.css integrity="sha256-uyABglTQSGQrm7TQfEkPeS1jgka+ZIcpQ+P+/o73wGQ="><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.af5d9722112bedac95702865c340bcd6286c4e9b2c15ce26b531ea1fba974cb8.js integrity="sha256-r12XIhEr7ayVcChlw0C81ihsTpssFc4mtTHqH7qXTLg=" data-copy=Copy data-copied=Copied></script><meta name=description content="
      
        Taekjun Kim, Wyeth Bair, Anitha Pasupathy Journal of Neuroscience
      
    "><link rel=canonical href=https://taekjunkim.github.io/publications/jneurosci_2022/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://taekjunkim.github.io/publications/jneurosci_2022/"><meta property="og:site_name" content="Taekjun Kim"><meta property="og:title" content="Perceptual Texture Dimensions Modulate Neuronal Response Dynamics in Visual Cortical Area V4"><meta property="og:description" content="Taekjun Kim, Wyeth Bair, Anitha Pasupathy Journal of Neuroscience"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="publications"><meta property="article:published_time" content="2022-01-26T00:00:00+00:00"><meta property="article:modified_time" content="2022-01-26T00:00:00+00:00"><meta property="article:tag" content="Primate"><meta property="article:tag" content="Texture"><meta property="article:tag" content="Temporal Dynamics"><meta property="article:tag" content="Perception"><meta property="article:tag" content="Electrophysiology"><meta property="article:tag" content="Area V4"><meta name=twitter:card content="summary"><meta name=twitter:title content="Perceptual Texture Dimensions Modulate Neuronal Response Dynamics in Visual Cortical Area V4"><meta name=twitter:description content="Taekjun Kim, Wyeth Bair, Anitha Pasupathy Journal of Neuroscience"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","articleSection":"Selected publications","name":"Perceptual Texture Dimensions Modulate Neuronal Response Dynamics in Visual Cortical Area V4","headline":"Perceptual Texture Dimensions Modulate Neuronal Response Dynamics in Visual Cortical Area V4","abstract":"Taekjun Kim, Wyeth Bair, Anitha Pasupathy \u003ccode\u003eJournal of Neuroscience\u003c\/code\u003e","inLanguage":"en","url":"https:\/\/taekjunkim.github.io\/publications\/jneurosci_2022\/","author":{"@type":"Person","name":"Taekjun Kim"},"copyrightYear":"2022","dateCreated":"2022-01-26T00:00:00\u002b00:00","datePublished":"2022-01-26T00:00:00\u002b00:00","dateModified":"2022-01-26T00:00:00\u002b00:00","keywords":["Primate","Texture","Temporal dynamics","Perception","Electrophysiology","area V4","Vision","Neuroscience"],"mainEntityOfPage":"true","wordCount":"1551"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://taekjunkim.github.io/","name":"","position":1},{"@type":"ListItem","item":"https://taekjunkim.github.io/publications/","name":"Selected Publications","position":2},{"@type":"ListItem","name":"Perceptual Texture Dimensions Modulate Neuronal Response Dynamics in Visual Cortical Area V4","position":3}]}</script><meta name=author content="Taekjun Kim"><link href=mailto:taekjunkim1223@gmail.com rel=me><link href=https://github.com/taekjunkim rel=me><link href=https://linkedin.com/in/taekjun-kim rel=me><link href="https://scholar.google.com/citations?user=pP442rIAAAAJ&amp;hl=en" rel=me></head><body class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"><div id=the-top class="absolute flex self-center"><a class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span>Skip to main content</a></div><header class="py-6 font-semibold text-neutral-900 dark:text-neutral sm:py-10 print:hidden"><nav class="flex items-start justify-between sm:items-center"><div class="flex flex-row items-center"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2" rel=me href=/>Taekjun Kim</a></div><ul class="flex list-none flex-col text-end sm:flex-row"><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/about/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">About Me</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/posts/ title=Posts><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Posts</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/publications/ title="Selected publications"><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Publications</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/tags/ title=Tags><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Tags</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><button id=search-button-1 title="Search (/)">
<span class="group-dark:hover:text-primary-400 transition-colors group-hover:text-primary-600"><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></span><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"></span></button></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><button id=appearance-switcher-1 type=button aria-label="appearance switcher">
<span class="group-dark:hover:text-primary-400 inline transition-colors group-hover:text-primary-600 dark:hidden" title="Switch to dark appearance"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg>
</span><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"></span>
</span><span class="group-dark:hover:text-primary-400 hidden transition-colors group-hover:text-primary-600 dark:inline" title="Switch to light appearance"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg>
</span><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"></span></span></button></li></ul></nav></header><div class="relative flex grow flex-col"><main id=main-content class=grow><article><header class=max-w-prose><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="hidden inline"><a class="dark:underline-neutral-600 decoration-neutral-300 hover:underline" href=/></a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="dark:underline-neutral-600 decoration-neutral-300 hover:underline" href=/publications/>Selected publications</a><span class="px-1 text-primary-500">/</span></li><li class="hidden inline"><a class="dark:underline-neutral-600 decoration-neutral-300 hover:underline" href=/publications/jneurosci_2022/>Perceptual Texture Dimensions Modulate Neuronal Response Dynamics in Visual Cortical Area V4</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mb-8 mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Perceptual Texture Dimensions Modulate Neuronal Response Dynamics in Visual Cortical Area V4</h1><div class="mb-10 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime="2022-01-26 00:00:00 +0000 UTC">26 January 2022</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">8 mins</span></div><div class="my-1 flex flex-wrap text-xs leading-relaxed text-neutral-500 dark:text-neutral-400"><a href=/tags/primate/ class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Primate</a>
<a href=/tags/texture/ class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Texture</a>
<a href=/tags/temporal-dynamics/ class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Temporal Dynamics</a>
<a href=/tags/perception/ class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Perception</a>
<a href=/tags/electrophysiology/ class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Electrophysiology</a>
<a href=/tags/area-v4/ class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Area V4</a>
<a href=/tags/vision/ class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Vision</a>
<a href=/tags/neuroscience/ class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Neuroscience</a></div></div></header><section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row"><div class="order-first px-0 lg:order-last lg:max-w-xs lg:ps-8"><div class="toc pe-5 lg:sticky lg:top-10 print:hidden"><details open class="-ms-5 mt-0 overflow-hidden rounded-lg ps-5"><summary class="block cursor-pointer bg-neutral-100 py-1 ps-5 text-lg font-semibold text-neutral-800 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="border-s border-dotted border-neutral-300 py-2 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#article-info>Article info</a></li><li><a href=#abstract>Abstract</a></li><li><a href=#figures>Figures</a><ul><li><a href=#fig1-visual-stimuli>Fig1. Visual stimuli</a></li><li><a href=#fig2-example-neuron-selective-for-coarse-textures>Fig2. Example neuron selective for coarse textures</a></li><li><a href=#fig3-example-neuron-selective-for-texture-contrast>Fig3. Example neuron selective for texture contrast</a></li><li><a href=#fig4-example-neuron-selective-for-nondirectional-textures>Fig4. Example neuron selective for nondirectional textures</a></li><li><a href=#fig5-example-neurons-selective-for-multiple-texture-features>Fig5. Example neurons selective for multiple texture features</a></li><li><a href=#fig6-population-results-relative-contribution-of-different-texture-attributes>Fig6. Population results: relative contribution of different texture attributes</a></li><li><a href=#fig7-population-results-temporal-dynamics-of-the-stepwise-regression-fit>Fig7. Population results: temporal dynamics of the stepwise regression fit</a></li><li><a href=#fig8-temporal-dynamics-the-frequency-of-significantly-modulated-neurons>Fig8. Temporal dynamics: the frequency of significantly modulated neurons</a></li><li><a href=#fig9-decoding-of-texture-category-from-population-responses>Fig9. Decoding of texture category from population responses</a></li></ul></li></ul></nav></div></details></div></div><div class="min-h-0 min-w-0 max-w-prose grow"><h2 id=article-info class="relative group">Article info <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#article-info aria-label=Anchor>#</a></span></h2><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><code>Authors</code></td><td>Taekjun Kim, Wyeth Bair, Anitha Pasupathy</td></tr><tr><td><code>Publication date</code></td><td>2022/01/26</td></tr><tr><td><code>Journal</code></td><td>Journal of Neuroscience</td></tr><tr><td><code>DOI</code></td><td><a href=https://doi.org/10.1523/JNEUROSCI.0971-21.2021 target=_blank rel=noreferrer>https://doi.org/10.1523/JNEUROSCI.0971-21.2021</a></td></tr></tbody></table><h2 id=abstract class="relative group">Abstract <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#abstract aria-label=Anchor>#</a></span></h2><p>Texture is an important visual attribute for surface pattern discrimination and therefore object segmentation, but the neural bases of texture perception are largely unknown. Previously, we demonstrated that the responses of V4 neurons to naturalistic texture patches are sensitive to four key features of human texture perception: coarseness, directionality, regularity, and contrast. To begin to understand how distinct texture perception emerges from the dynamics of neuronal responses, in 2 macaque monkeys (1 male, 1 female), we investigated the relative contribution of the four texture attributes to V4 responses in terms of the strength and timing of response modulation. We found that the different feature dimensions are associated with different temporal dynamics. Specifically, the response modulation associated with directionality and regularity was significantly delayed relative to that associated with coarseness and contrast, suggesting that the latter are fundamentally simpler feature dimensions. The population of texture-selective neurons could be grouped into multiple clusters based on the combination of feature dimensions encoded, and those subpopulations displayed distinct temporal dynamics characterized by the weighted combinations of multiple features. Finally, we applied a population decoding approach to demonstrate that texture category information can be obtained from short temporal windows across time. These results demonstrate that the representation of different perceptually relevant texture features emerge over time in the responses of V4 neurons. The observed temporal organization provides a framework to interpret how the processing of surface features unfolds in early and midlevel cortical stages, and could ultimately inform the interpretation of perceptual texture dynamics.</p><h2 id=figures class="relative group">Figures <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#figures aria-label=Anchor>#</a></span></h2><h3 id=fig1-visual-stimuli class="relative group">Fig1. Visual stimuli <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig1-visual-stimuli aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset="/publications/jneurosci_2022/F1.large_hu_d18febf9a5ed00c8.webp 330w,/publications/jneurosci_2022/F1.large_hu_21cdc2c230423cde.webp 660w
,/publications/jneurosci_2022/F1.large_hu_e11ca740dbb2ad19.webp 1024w
,/publications/jneurosci_2022/F1.large_hu_422d051f7c1ecbc3.webp 1280w" sizes=100vw type=image/webp><img width=1280 height=965 class="mx-auto my-0 rounded-md" alt=Fig1 loading=lazy decoding=async src=/publications/jneurosci_2022/F1.large_hu_3f3c58ccb79dbbd6.jpg srcset="/publications/jneurosci_2022/F1.large_hu_2bdd4c22aa9bd05c.jpg 330w,/publications/jneurosci_2022/F1.large_hu_3f3c58ccb79dbbd6.jpg 660w
,/publications/jneurosci_2022/F1.large_hu_1018b710a0cdbc76.jpg 1024w
,/publications/jneurosci_2022/F1.large.jpg 1280w" sizes=100vw></picture></figure><font size=2>We used a set of 21 textures to study responses of V4 neurons. The ordering of textures along the four dimensions is shown: (<strong>A</strong>) coarseness, (<strong>B</strong>) directionality, (<strong>C</strong>) regularity, and (<strong>D</strong>) contrast. Along each axis, textures are rank-ordered; in A from fine to coarse, etc. Numbers below each texture image indicate the raw index value along each axis. Gray triangles represent the corresponding z-scored value. Red triangles represent the median texture and the corresponding z-scored value along each axis. Each texture was presented in four orientations for a total of 84 stimuli (see Materials and Methods).</font></p><h3 id=fig2-example-neuron-selective-for-coarse-textures class="relative group">Fig2. Example neuron selective for coarse textures <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig2-example-neuron-selective-for-coarse-textures aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset="/publications/jneurosci_2022/F2.large_hu_7486eb6562b79ccb.webp 330w,/publications/jneurosci_2022/F2.large_hu_799a413f84983f9e.webp 660w
,/publications/jneurosci_2022/F2.large_hu_81d37179dbd95e8b.webp 1020w
,/publications/jneurosci_2022/F2.large_hu_81d37179dbd95e8b.webp 1020w" sizes=100vw type=image/webp><img width=1020 height=1280 class="mx-auto my-0 rounded-md" alt=Fig2 loading=lazy decoding=async src=/publications/jneurosci_2022/F2.large_hu_b4345a9c850c364b.jpg srcset="/publications/jneurosci_2022/F2.large_hu_c3d98f5a1070ebb3.jpg 330w,/publications/jneurosci_2022/F2.large_hu_b4345a9c850c364b.jpg 660w
,/publications/jneurosci_2022/F2.large.jpg 1020w
,/publications/jneurosci_2022/F2.large.jpg 1020w" sizes=100vw></picture></figure><font size=2><strong>A,</strong> PSTHs are shown for the 84 texture stimuli. All panels represent the same data but differently ordered in accordance with the rank-ordering in Figure 1 (i.e., in ascending order of the index value along each of the four texture dimensions). From top to bottom for each panel, textures run from fine to coarse, nondirectional to directional, irregular to regular, and low-contrast to high-contrast, respectively. Color represents response strength in accordance with the scale bar. Responses are smoothed with a Gaussian of σ = 5 ms.
<strong>B,</strong> Average PSTHs for the top and bottom halves along each texture dimension are shown in blue and red, respectively. For example, in the first panel at left, blue and red represent responses to fine and coarse textures, respectively. Black asterisks indicate time points with significant difference between red and blue curves (Mann–Whitney U test in a 30 ms sliding window, p &lt; 0.05). Statistically significant difference between responses to coarse and fine textures emerged 41 ms after stimulus onset.
<strong>C,</strong> The 20 most (top) and least (bottom) preferred textures based on the number of spikes during the 50-150 ms window after stimulus onset (shading in B) are shown.
<strong>D,</strong> Scatter plots represent neuronal responses to all texture stimuli during the 50-150 ms window as a function of each texture index. Filled symbols represent the 20 preferred and nonpreferred textures shown in <strong>C</strong>.</font></p><h3 id=fig3-example-neuron-selective-for-texture-contrast class="relative group">Fig3. Example neuron selective for texture contrast <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig3-example-neuron-selective-for-texture-contrast aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset="/publications/jneurosci_2022/F3.large_hu_66ab8873650da5ae.webp 330w,/publications/jneurosci_2022/F3.large_hu_9434701ae9f87217.webp 660w
,/publications/jneurosci_2022/F3.large_hu_b96d2fc0a225bab1.webp 1024w
,/publications/jneurosci_2022/F3.large_hu_d7047e1a03b8c932.webp 1050w" sizes=100vw type=image/webp><img width=1050 height=1280 class="mx-auto my-0 rounded-md" alt=Fig3 loading=lazy decoding=async src=/publications/jneurosci_2022/F3.large_hu_167dedd72451dbc9.jpg srcset="/publications/jneurosci_2022/F3.large_hu_13e89d58ccb5acee.jpg 330w,/publications/jneurosci_2022/F3.large_hu_167dedd72451dbc9.jpg 660w
,/publications/jneurosci_2022/F3.large_hu_179d77ea3d5d1fe4.jpg 1024w
,/publications/jneurosci_2022/F3.large.jpg 1050w" sizes=100vw></picture></figure><font size=2>Low-contrast textures evoked stronger responses from Neuron 2 compared with high-contrast textures (<strong>A,B,</strong> rightmost panels). Statistically significant difference between responses to low- and high-contrast textures emerged 43 ms after stimulus onset. A mild preference for coarse textures is notable later in the response. All conventions are as in Figure 2. <strong>C,</strong> The 20 most and least preferred textures are shown based on the number of spikes during the 50-150 ms window after stimulus onset (shading in B). <strong>D,</strong> Scatter plots represent neuronal responses to all texture stimuli during the 50-150 ms window as a function of each texture index. Filled symbols represent the 20 preferred and nonpreferred textures shown in <strong>C</strong>.</font></p><h3 id=fig4-example-neuron-selective-for-nondirectional-textures class="relative group">Fig4. Example neuron selective for nondirectional textures <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig4-example-neuron-selective-for-nondirectional-textures aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset="/publications/jneurosci_2022/F4.large_hu_d75afbedfe5417b3.webp 330w,/publications/jneurosci_2022/F4.large_hu_629b579e1cc32364.webp 660w
,/publications/jneurosci_2022/F4.large_hu_1ef931a7b7f0166c.webp 1024w
,/publications/jneurosci_2022/F4.large_hu_aa02e85182742fa6.webp 1032w" sizes=100vw type=image/webp><img width=1032 height=1280 class="mx-auto my-0 rounded-md" alt=Fig4 loading=lazy decoding=async src=/publications/jneurosci_2022/F4.large_hu_15c483c354ddaaac.jpg srcset="/publications/jneurosci_2022/F4.large_hu_1ed3d24b1ccd57db.jpg 330w,/publications/jneurosci_2022/F4.large_hu_15c483c354ddaaac.jpg 660w
,/publications/jneurosci_2022/F4.large_hu_4b68ee3b12be4624.jpg 1024w
,/publications/jneurosci_2022/F4.large.jpg 1032w" sizes=100vw></picture></figure><font size=2><strong>A, B,</strong> Textures lacking directional information evoked stronger responses from Neuron 3. Statistically significant difference between responses to nondirectional and directional textures emerged 109 ms after stimulus onset. <strong>C,</strong> The 20 most and least preferred textures are shown based on the number of spikes during the 100-400 ms window after stimulus onset (shading in B). All conventions are as in Figure 2. <strong>D,</strong> Scatter plots represent neuronal responses to all texture stimuli during the 100-400 ms window as a function of each texture index. Filled symbols represent the 20 preferred and nonpreferred textures shown in <strong>C</strong>.</font></p><h3 id=fig5-example-neurons-selective-for-multiple-texture-features class="relative group">Fig5. Example neurons selective for multiple texture features <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig5-example-neurons-selective-for-multiple-texture-features aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset=/publications/jneurosci_2022/F5.large_hu_a1d990b8999d25b.webp sizes=100vw type=image/webp><img width=635 height=1280 class="mx-auto my-0 rounded-md" alt=Fig5 loading=lazy decoding=async src=/publications/jneurosci_2022/F5.large.jpg></picture></figure><font size=2><strong>A, B,</strong> Coarse and irregular textures evoke strong responses from Neuron 4. Statistically significant difference between responses to coarse and fine textures emerged 52 ms after stimulus onset, whereas that between regular and irregular textures emerged later, at 100 ms. Statistically significant difference in response between directional and nondirectional textures is also evident, but this can be explained by the correlation between directionality and regularity in our stimulus set (see Results). <strong>C-F,</strong> Scatter plots show mean neuronal responses to all texture stimuli during the 50-150 ms (<strong>D</strong>) or 100-400 ms (<strong>F</strong>) epoch after stimulus onset as a function of each texture index. The 20 most and least preferred textures based on early activity (<strong>C</strong>) and later activity (<strong>E</strong>) are shown. All conventions are as in Figure 2.</font></p><h3 id=fig6-population-results-relative-contribution-of-different-texture-attributes class="relative group">Fig6. Population results: relative contribution of different texture attributes <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig6-population-results-relative-contribution-of-different-texture-attributes aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset="/publications/jneurosci_2022/F6.large_hu_3f5a1f5e1f93b86b.webp 330w,/publications/jneurosci_2022/F6.large_hu_b2883b7ed4bccee6.webp 660w
,/publications/jneurosci_2022/F6.large_hu_827f2279461e2eab.webp 1024w
,/publications/jneurosci_2022/F6.large_hu_485359f64db03a93.webp 1280w" sizes=100vw type=image/webp><img width=1280 height=702 class="mx-auto my-0 rounded-md" alt=Fig6 loading=lazy decoding=async src=/publications/jneurosci_2022/F6.large_hu_f8cebb9a26c51df2.jpg srcset="/publications/jneurosci_2022/F6.large_hu_8b5b231877b76bc7.jpg 330w,/publications/jneurosci_2022/F6.large_hu_f8cebb9a26c51df2.jpg 660w
,/publications/jneurosci_2022/F6.large_hu_702c3d2ef5364594.jpg 1024w
,/publications/jneurosci_2022/F6.large.jpg 1280w" sizes=100vw></picture></figure><font size=2><strong>A,</strong> Fitted weights for the four texture attributes based on the stepwise regression analysis for individual neurons are shown (see Materials and Methods). Models were based on neuronal responses in the 50-400 ms window after stimulus onset. Red and blue represent positive and negative weights, respectively (see color bar). Grayscale represents goodness of fit in terms of the correlation coefficient (Pearson&rsquo;s r) between the observed and predicted responses for each neuron. Neurons (N1-N4) corresponding to examples in Figure 2-5 are identified. <strong>B,</strong> Pie plot represents relative proportions (and numbers) of neurons encoding single or multiple texture features based on the number of coefficients deemed significant in the stepwise regression model. <strong>C,</strong> Tabulation of the frequency of the different combinations of feature dimensions that provided the best fit for neuronal responses based on the regression models. <strong>D,</strong> Distribution of goodness-of-fit values quantified by the correlation coefficient (r) between the observed and predicted data values from the 108 neurons with a statistically significant stepwise regression fit. Red dashed line indicates the median value, 0.50. <strong>E,</strong> The relative proportions of positive and negative weights for each texture attribute.</font></p><h3 id=fig7-population-results-temporal-dynamics-of-the-stepwise-regression-fit class="relative group">Fig7. Population results: temporal dynamics of the stepwise regression fit <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig7-population-results-temporal-dynamics-of-the-stepwise-regression-fit aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset="/publications/jneurosci_2022/F7.large_hu_cc2d373f9a29f2f2.webp 330w,/publications/jneurosci_2022/F7.large_hu_3920009bdabefe03.webp 660w
,/publications/jneurosci_2022/F7.large_hu_dd5b6492071d39b0.webp 1024w
,/publications/jneurosci_2022/F7.large_hu_98120e2d48f72fbc.webp 1280w" sizes=100vw type=image/webp><img width=1280 height=1009 class="mx-auto my-0 rounded-md" alt=Fig7 loading=lazy decoding=async src=/publications/jneurosci_2022/F7.large_hu_bf41a47f8c4dc88c.jpg srcset="/publications/jneurosci_2022/F7.large_hu_a67f401629f344e.jpg 330w,/publications/jneurosci_2022/F7.large_hu_bf41a47f8c4dc88c.jpg 660w
,/publications/jneurosci_2022/F7.large_hu_dac9bf909fb0ca7b.jpg 1024w
,/publications/jneurosci_2022/F7.large.jpg 1280w" sizes=100vw></picture></figure><font size=2><strong>A,</strong> The fitted weights for the four attributes based on the stepwise regression model fit for individual neurons. Models were based on neuronal responses in the 50-400 ms window after stimulus onset (same as in Fig. 6A). <strong>B,</strong> Weights as a function of time for the four texture attributes based on the stepwise regression fit. Models were based on neuronal responses within a 100 ms sliding window from –100 to 500 ms sliding in 10 ms increments. Red and blue represent positive and negative weights, respectively. <strong>C,</strong> Variance in texture weights across neurons (Var_wt) is shown as a function of time for each of the four texture dimensions. High values of Varwt are an indicator of the emergence of selectivity. <strong>D,</strong> Var_wt, normalized by the maximum across texture attributes, is plotted to facilitate direct comparison of the temporal dynamics. Varwt for coarseness and contrast rose rapidly and reached the maximum values no later than 100 ms after stimulus onset, whereas those for directionality and regularity evolved more slowly and reached the maximum values at ∼150 ms after stimulus onset.</font></p><h3 id=fig8-temporal-dynamics-the-frequency-of-significantly-modulated-neurons class="relative group">Fig8. Temporal dynamics: the frequency of significantly modulated neurons <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig8-temporal-dynamics-the-frequency-of-significantly-modulated-neurons aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset="/publications/jneurosci_2022/F8.large_hu_53392670600e84cd.webp 330w,/publications/jneurosci_2022/F8.large_hu_59be51f246fce00b.webp 660w
,/publications/jneurosci_2022/F8.large_hu_c34fa52a3e4aae75.webp 1024w
,/publications/jneurosci_2022/F8.large_hu_33b14b59c58c2ae5.webp 1280w" sizes=100vw type=image/webp><img width=1280 height=320 class="mx-auto my-0 rounded-md" alt=Fig8 loading=lazy decoding=async src=/publications/jneurosci_2022/F8.large_hu_7f8fd47d2325957d.jpg srcset="/publications/jneurosci_2022/F8.large_hu_1c32a1ea5f7954ca.jpg 330w,/publications/jneurosci_2022/F8.large_hu_7f8fd47d2325957d.jpg 660w
,/publications/jneurosci_2022/F8.large_hu_204362d76917c582.jpg 1024w
,/publications/jneurosci_2022/F8.large.jpg 1280w" sizes=100vw></picture></figure><font size=2><strong>A-D,</strong> The number of significantly modulated neurons as a function of time for each texture dimension. Red lines at 100 ms after the stimulus onset are included to facilitate comparison across panels.</font></p><h3 id=fig9-decoding-of-texture-category-from-population-responses class="relative group">Fig9. Decoding of texture category from population responses <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig9-decoding-of-texture-category-from-population-responses aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset="/publications/jneurosci_2022/F9.large_hu_2c198168c16ab780.webp 330w,/publications/jneurosci_2022/F9.large_hu_8a76ed7a525a2984.webp 660w
,/publications/jneurosci_2022/F9.large_hu_21a6fc290a0601eb.webp 1024w
,/publications/jneurosci_2022/F9.large_hu_94509091cec158a3.webp 1280w" sizes=100vw type=image/webp><img width=1280 height=500 class="mx-auto my-0 rounded-md" alt=Fig9 loading=lazy decoding=async src=/publications/jneurosci_2022/F9.large_hu_54385d17d64d2a40.jpg srcset="/publications/jneurosci_2022/F9.large_hu_5127611143d08b16.jpg 330w,/publications/jneurosci_2022/F9.large_hu_54385d17d64d2a40.jpg 660w
,/publications/jneurosci_2022/F9.large_hu_5563eff781e12e0.jpg 1024w
,/publications/jneurosci_2022/F9.large.jpg 1280w" sizes=100vw></picture></figure><font size=2><strong>A,</strong> Decoding accuracy of SVM classifiers for each of the four texture dimensions is plotted as a function of population size. At each size, neurons were sampled with replacement to generate a simulated subpopulation, and an SVM was trained to assign each texture to one of two categories along each texture dimension (e.g., coarse vs fine) based on spiking responses during the 50-400 ms window after stimulus onset. The simulation was repeated 100 times, and the average cross-validation scores were obtained for each texture dimension. Error bars indicate SEM. <strong>B,</strong> Time course of SVM classifier performance was quantified using a sliding window (bin width: 30 ms, step size: 1 ms) for a population size of 60 neurons. The simulation was repeated 100 times, and the average cross-validation scores were obtained for each texture dimension. Shaded area represents ± 1 SEM. Arrows indicate the peak proportion correct for each curve.</font></p></div></section><footer class="max-w-prose pt-8 print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="group flex" href=/publications/annurevvissci_2020/><span class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&larr;</span><span class="ltr:hidden rtl:inline">&rarr;</span></span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Visual functions of primate area V4</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2020-09-15 00:00:00 +0000 UTC">15 September 2020</time>
</span></span></a></span><span><a class="group flex text-right" href=/publications/currbio_2023/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Dissociation in neuronal encoding of object versus surface motion in the primate brain</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2023-02-03 00:00:00 +0000 UTC">3 February 2023</time>
</span></span><span class="ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[-2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&rarr;</span><span class="ltr:hidden rtl:inline">&larr;</span></span></a></span></div></div></footer></article></main><div class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12" id=to-top hidden=true><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div><footer class="py-10 print:hidden"><div class="flex items-center justify-between"><div><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Taekjun Kim</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://github.com/jpanther/congo target=_blank rel="noopener noreferrer">Congo</a></p></div><div class="flex flex-row items-center"></div></div></footer><div id=search-wrapper class="invisible fixed inset-0 z-50 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://taekjunkim.github.io/><div id=search-modal class="top-20 mx-auto flex min-h-0 w-full max-w-3xl flex-col rounded-md border border-neutral-200 bg-neutral shadow-lg dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex flex-none items-center justify-between px-2"><form class="flex min-w-0 flex-auto items-center"><div class="flex h-8 w-8 items-center justify-center text-neutral-400"><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="mx-1 flex h-12 flex-auto appearance-none bg-transparent focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex h-8 w-8 items-center justify-center text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto overflow-auto px-2"><ul id=search-results></ul></section></div></div></div></body></html>