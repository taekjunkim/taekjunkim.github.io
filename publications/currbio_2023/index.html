<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="#FFFFFF"><title>Dissociation in neuronal encoding of object versus surface motion in the primate brain &#183; Taekjun Kim</title>
<meta name=title content="Dissociation in neuronal encoding of object versus surface motion in the primate brain &#183; Taekjun Kim"><script type=text/javascript src=/js/appearance.min.8a082f81b27f3cb2ee528df0b0bdc39787034cf2cc34d4669fbc9977c929023c.js integrity="sha256-iggvgbJ/PLLuUo3wsL3Dl4cDTPLMNNRmn7yZd8kpAjw="></script><link type=text/css rel=stylesheet href=/css/main.bundle.min.bb20018254d048642b9bb4d07c490f792d638246be64872943e3fefe8ef7c064.css integrity="sha256-uyABglTQSGQrm7TQfEkPeS1jgka+ZIcpQ+P+/o73wGQ="><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.af5d9722112bedac95702865c340bcd6286c4e9b2c15ce26b531ea1fba974cb8.js integrity="sha256-r12XIhEr7ayVcChlw0C81ihsTpssFc4mtTHqH7qXTLg=" data-copy=Copy data-copied=Copied></script><meta name=description content="
      
        Anthony Bigelow*, Taekjun Kim*, Tomoyuki Namima, Wyeth Bair, Anitha Pasupathy Current Biology
      
    "><link rel=canonical href=https://taekjunkim.github.io/publications/currbio_2023/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://taekjunkim.github.io/publications/currbio_2023/"><meta property="og:site_name" content="Taekjun Kim"><meta property="og:title" content="Dissociation in neuronal encoding of object versus surface motion in the primate brain"><meta property="og:description" content="Anthony Bigelow*, Taekjun Kim*, Tomoyuki Namima, Wyeth Bair, Anitha Pasupathy Current Biology"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="publications"><meta property="article:published_time" content="2023-02-03T00:00:00+00:00"><meta property="article:modified_time" content="2023-02-03T00:00:00+00:00"><meta property="article:tag" content="Primate"><meta property="article:tag" content="Motion"><meta property="article:tag" content="Electrophysiology"><meta property="article:tag" content="Area V4"><meta property="article:tag" content="Vision"><meta property="article:tag" content="Neuroscience"><meta name=twitter:card content="summary"><meta name=twitter:title content="Dissociation in neuronal encoding of object versus surface motion in the primate brain"><meta name=twitter:description content="Anthony Bigelow*, Taekjun Kim*, Tomoyuki Namima, Wyeth Bair, Anitha Pasupathy Current Biology"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","articleSection":"Selected publications","name":"Dissociation in neuronal encoding of object versus surface motion in the primate brain","headline":"Dissociation in neuronal encoding of object versus surface motion in the primate brain","abstract":"Anthony Bigelow*, Taekjun Kim*, Tomoyuki Namima, Wyeth Bair, Anitha Pasupathy \u003ccode\u003eCurrent Biology\u003c\/code\u003e","inLanguage":"en","url":"https:\/\/taekjunkim.github.io\/publications\/currbio_2023\/","author":{"@type":"Person","name":"Taekjun Kim"},"copyrightYear":"2023","dateCreated":"2023-02-03T00:00:00\u002b00:00","datePublished":"2023-02-03T00:00:00\u002b00:00","dateModified":"2023-02-03T00:00:00\u002b00:00","keywords":["Primate","Motion","Electrophysiology","area V4","Vision","Neuroscience"],"mainEntityOfPage":"true","wordCount":"1051"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://taekjunkim.github.io/","name":"","position":1},{"@type":"ListItem","item":"https://taekjunkim.github.io/publications/","name":"Selected Publications","position":2},{"@type":"ListItem","name":"Dissociation in Neuronal Encoding of Object Versus Surface Motion in the Primate Brain","position":3}]}</script><meta name=author content="Taekjun Kim"><link href=mailto:taekjunkim1223@gmail.com rel=me><link href=https://github.com/taekjunkim rel=me><link href=https://linkedin.com/in/taekjun-kim rel=me><link href="https://scholar.google.com/citations?user=pP442rIAAAAJ&amp;hl=en" rel=me></head><body class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"><div id=the-top class="absolute flex self-center"><a class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span>Skip to main content</a></div><header class="py-6 font-semibold text-neutral-900 dark:text-neutral sm:py-10 print:hidden"><nav class="flex items-start justify-between sm:items-center"><div class="flex flex-row items-center"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2" rel=me href=/>Taekjun Kim</a></div><ul class="flex list-none flex-col text-end sm:flex-row"><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/about/ title><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">About Me</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/posts/ title=Posts><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Posts</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/publications/ title="Selected publications"><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Publications</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/tags/ title=Tags><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Tags</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><button id=search-button-1 title="Search (/)">
<span class="group-dark:hover:text-primary-400 transition-colors group-hover:text-primary-600"><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></span><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"></span></button></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><button id=appearance-switcher-1 type=button aria-label="appearance switcher">
<span class="group-dark:hover:text-primary-400 inline transition-colors group-hover:text-primary-600 dark:hidden" title="Switch to dark appearance"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg>
</span><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"></span>
</span><span class="group-dark:hover:text-primary-400 hidden transition-colors group-hover:text-primary-600 dark:inline" title="Switch to light appearance"><span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg>
</span><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"></span></span></button></li></ul></nav></header><div class="relative flex grow flex-col"><main id=main-content class=grow><article><header class=max-w-prose><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="hidden inline"><a class="dark:underline-neutral-600 decoration-neutral-300 hover:underline" href=/></a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="dark:underline-neutral-600 decoration-neutral-300 hover:underline" href=/publications/>Selected publications</a><span class="px-1 text-primary-500">/</span></li><li class="hidden inline"><a class="dark:underline-neutral-600 decoration-neutral-300 hover:underline" href=/publications/currbio_2023/>Dissociation in neuronal encoding of object versus surface motion in the primate brain</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mb-8 mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Dissociation in neuronal encoding of object versus surface motion in the primate brain</h1><div class="mb-10 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime="2023-02-03 00:00:00 +0000 UTC">3 February 2023</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">5 mins</span></div><div class="my-1 flex flex-wrap text-xs leading-relaxed text-neutral-500 dark:text-neutral-400"><a href=/tags/primate/ class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Primate</a>
<a href=/tags/motion/ class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Motion</a>
<a href=/tags/electrophysiology/ class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Electrophysiology</a>
<a href=/tags/area-v4/ class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Area V4</a>
<a href=/tags/vision/ class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Vision</a>
<a href=/tags/neuroscience/ class="mx-1 my-1 rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Neuroscience</a></div></div></header><section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row"><div class="order-first px-0 lg:order-last lg:max-w-xs lg:ps-8"><div class="toc pe-5 lg:sticky lg:top-10 print:hidden"><details open class="-ms-5 mt-0 overflow-hidden rounded-lg ps-5"><summary class="block cursor-pointer bg-neutral-100 py-1 ps-5 text-lg font-semibold text-neutral-800 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="border-s border-dotted border-neutral-300 py-2 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#article-info>Article info</a></li><li><a href=#abstract>Abstract</a></li><li><a href=#figures>Figures</a><ul><li><a href=#fig1-v4-responses-to-long-range-motion-stimuli>Fig1. V4 responses to long-range motion stimuli</a></li><li><a href=#fig2-comparison-of-mt-and-v4-data>Fig2. Comparison of MT and V4 data</a></li><li><a href=#fig3-direction-selectivity-for-object-motion-across-spatiotemporal-scales>Fig3. Direction selectivity for object motion across spatiotemporal scales</a></li><li><a href=#fig4-v4-direction-sensitivity-for-object-versus-surface-motion-and-chromatic-boundaries>Fig4. V4 direction sensitivity for object versus surface motion and chromatic boundaries</a></li><li><a href=#fig5-position-invariance-of-motion-direction-selectivity>Fig5. Position invariance of motion direction selectivity</a></li><li><a href=#fig6-population-decoding-of-object-motion-direction>Fig6. Population decoding of object motion direction</a></li></ul></li></ul></nav></div></details></div></div><div class="min-h-0 min-w-0 max-w-prose grow"><h2 id=article-info class="relative group">Article info <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#article-info aria-label=Anchor>#</a></span></h2><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><code>Authors</code></td><td>Anthony Bigelow*, Taekjun Kim*, Tomoyuki Namima, Wyeth Bair, Anitha Pasupathy</td></tr><tr><td><code>Publication date</code></td><td>2023/02/03</td></tr><tr><td><code>Journal</code></td><td>Current Biology</td></tr><tr><td><code>DOI</code></td><td><a href=https://doi.org/10.1016/j.cub.2023.01.016 target=_blank rel=noreferrer>https://doi.org/10.1016/j.cub.2023.01.016</a></td></tr></tbody></table><p>* <em>These authors contributed equally</em></p><h2 id=abstract class="relative group">Abstract <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#abstract aria-label=Anchor>#</a></span></h2><p>A paradox exists in our understanding of motion processing in the primate visual system: neurons in the dorsal motion processing stream often strikingly fail to encode long-range and perceptually salient jumps of a moving stimulus. Psychophysical studies suggest that such long-range motion, which requires integration over more distant parts of the visual field, may be based on higher-order motion processing mechanisms that rely on feature or object tracking. Here, we demonstrate that ventral visual area V4, long recognized as critical for processing static scenes, includes neurons that maintain direction selectivity for long-range motion, even when conflicting local motion is present. These V4 neurons exhibit specific selectivity for the motion of objects, i.e., targets with defined boundaries, rather than the motion of surfaces behind apertures, and are selective for direction of motion over a broad range of spatial displacements and defined by a variety of features. Motion direction at a range of speeds can be accurately decoded on single trials from the activity of just a few V4 neurons. Thus, our results identify a novel motion computation in the ventral stream that is strikingly different from, and complementary to, the well-established system in the dorsal stream, and they support the hypothesis that the ventral stream system interacts with the dorsal stream to achieve the higher level of abstraction critical for tracking dynamic objects.</p><h2 id=figures class="relative group">Figures <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#figures aria-label=Anchor>#</a></span></h2><h3 id=fig1-v4-responses-to-long-range-motion-stimuli class="relative group">Fig1. V4 responses to long-range motion stimuli <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig1-v4-responses-to-long-range-motion-stimuli aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset="/publications/currbio_2023/gr1_lrg_hu_3a78815b2df9cb3f.webp 330w,/publications/currbio_2023/gr1_lrg_hu_81b6233a3c0b5c31.webp 660w
,/publications/currbio_2023/gr1_lrg_hu_34165b8f83f1b0f1.webp 1024w
,/publications/currbio_2023/gr1_lrg_hu_40bc8d71e29cbf3f.webp 1320w" sizes=100vw type=image/webp><img width=2875 height=3711 class="mx-auto my-0 rounded-md" alt=Fig1 loading=lazy decoding=async src=/publications/currbio_2023/gr1_lrg_hu_e80c7e47c2903241.jpg srcset="/publications/currbio_2023/gr1_lrg_hu_7e0cb8aef64197e4.jpg 330w,/publications/currbio_2023/gr1_lrg_hu_e80c7e47c2903241.jpg 660w
,/publications/currbio_2023/gr1_lrg_hu_3fc69a5607321870.jpg 1024w
,/publications/currbio_2023/gr1_lrg_hu_72eef5510be723e1.jpg 1320w" sizes=100vw></picture></figure><font size=2><strong>A,</strong> Stimulus design. An elliptical patch was displayed in sequence at seven locations centered on the RF (white circle, shown for illustration only). At each location, the stimulus was presented for 100 ms before disappearing and reappearing at the next location instantaneously. Spatial displacements were scaled to a third of the estimated RF diameter. Eight directions were tested; opposite directions sampled identical locations.<br><strong>B,</strong> Mean responses and SEM of five example neurons (rows) to long-range motion (LRM_noise and LRM_sinusoid) and drifting sinusoidal gratings (local). When LRM was combined with local motion in the same or opposite directions (LRM_sinusoid + local), tuning for LRM was similar. Dashed lines: baseline.
<strong>C,</strong> Population data. Histograms of DI values for LRM and local stimuli. Black/gray bars (and corresponding numbers) show neurons with/without statistically significant modulation by motion direction (one-way ANOVA, p &lt; 0.05). Arrows: median DI across the dataset. Numbers in parentheses show neurons with DI ≥ 0.5 and statistically significant modulation.</font></p><h3 id=fig2-comparison-of-mt-and-v4-data class="relative group">Fig2. Comparison of MT and V4 data <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig2-comparison-of-mt-and-v4-data aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset="/publications/currbio_2023/gr2_lrg_hu_a53c1fe715f739d.webp 330w,/publications/currbio_2023/gr2_lrg_hu_8d217d367c5899e4.webp 660w
,/publications/currbio_2023/gr2_lrg_hu_288798d84b8853c8.webp 1024w
,/publications/currbio_2023/gr2_lrg_hu_f798715b1e6c8e80.webp 1320w" sizes=100vw type=image/webp><img width=1484 height=2994 class="mx-auto my-0 rounded-md" alt=Fig2 loading=lazy decoding=async src=/publications/currbio_2023/gr2_lrg_hu_bedfc056a0fa9980.jpg srcset="/publications/currbio_2023/gr2_lrg_hu_5b4bdb6710222f37.jpg 330w,/publications/currbio_2023/gr2_lrg_hu_bedfc056a0fa9980.jpg 660w
,/publications/currbio_2023/gr2_lrg_hu_ca2eb359da691a67.jpg 1024w
,/publications/currbio_2023/gr2_lrg_hu_aaaa7b6bd9662e.jpg 1320w" sizes=100vw></picture></figure><font size=2><strong>A,</strong> Size of the spatial displacement (dX) is plotted against DILRM_noise for each of the neurons in Figure 1. Filled symbols denote neurons that exhibit responses significantly modulated by motion direction (one-way ANOVA, p &lt; 0.05). The shaded area represents moderate direction selectivity (DI ≥ 0.5). Red arrow denotes the range (0.25°–1°) of maximum dX values in V1 and MT.
<strong>B,</strong> Local dominance histograms for V4 data (top) from this study versus MT data (bottom), reproduced with permission from Hedges et al. DI values for LRM_sinusoid and local were calculated as in Hedges et al. For MT, local dominance is centered around 1, suggesting much stronger selectivity for local than LRM, unlike for V4 data.</font></p><h3 id=fig3-direction-selectivity-for-object-motion-across-spatiotemporal-scales class="relative group">Fig3. Direction selectivity for object motion across spatiotemporal scales <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig3-direction-selectivity-for-object-motion-across-spatiotemporal-scales aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset="/publications/currbio_2023/gr3_lrg_hu_8e162d031b00046f.webp 330w,/publications/currbio_2023/gr3_lrg_hu_daa96e92d135cd77.webp 660w
,/publications/currbio_2023/gr3_lrg_hu_71fe68584e15074b.webp 1024w
,/publications/currbio_2023/gr3_lrg_hu_40753c10d2ce6688.webp 1320w" sizes=100vw type=image/webp><img width=2875 height=3265 class="mx-auto my-0 rounded-md" alt=Fig3 loading=lazy decoding=async src=/publications/currbio_2023/gr3_lrg_hu_7d3db2d11ca3921e.jpg srcset="/publications/currbio_2023/gr3_lrg_hu_9707db424869aa22.jpg 330w,/publications/currbio_2023/gr3_lrg_hu_7d3db2d11ca3921e.jpg 660w
,/publications/currbio_2023/gr3_lrg_hu_b8cfb707502e34c5.jpg 1024w
,/publications/currbio_2023/gr3_lrg_hu_37a8f05aff3dc1f4.jpg 1320w" sizes=100vw></picture></figure><font size=2><strong>A,</strong> Schematic of the Neuropixels probe showing a subset of the 384 contact pairs (black and white squares) along the shank. <strong>B,</strong> Waveforms of six example neurons (colors) detected at multiple nearby contacts. Numbers indicate the contact associated with the largest amplitude waveforms.
<strong>C,</strong> Mean responses of example neurons as a function of motion direction for longer range (gray) and shorter range (white) object motion, and local gratings (yellow). Corresponding spatial step sizes (dX) are shown. Error bars: SEM.
<strong>D,</strong> Distribution of DI values. Black/gray bars (and n) show neurons with/without statistically significant modulation of responses by motion direction (one-way ANOVA, p &lt; 0.05). arrows: median DI across the dataset. Numbers in parentheses show neurons with DI ≥ 0.5 and statistically significant modulation.</font></p><h3 id=fig4-v4-direction-sensitivity-for-object-versus-surface-motion-and-chromatic-boundaries class="relative group">Fig4. V4 direction sensitivity for object versus surface motion and chromatic boundaries <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig4-v4-direction-sensitivity-for-object-versus-surface-motion-and-chromatic-boundaries aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset="/publications/currbio_2023/gr4_lrg_hu_1b09961b934d4439.webp 330w,/publications/currbio_2023/gr4_lrg_hu_dfcae4504c4fce8e.webp 660w
,/publications/currbio_2023/gr4_lrg_hu_2202cccedea3874a.webp 1024w
,/publications/currbio_2023/gr4_lrg_hu_7374141b2dc11124.webp 1320w" sizes=100vw type=image/webp><img width=3375 height=1300 class="mx-auto my-0 rounded-md" alt=Fig4 loading=lazy decoding=async src=/publications/currbio_2023/gr4_lrg_hu_b6366870ef78dcc9.jpg srcset="/publications/currbio_2023/gr4_lrg_hu_346c4d92c8a8e69c.jpg 330w,/publications/currbio_2023/gr4_lrg_hu_b6366870ef78dcc9.jpg 660w
,/publications/currbio_2023/gr4_lrg_hu_80edf2ab2a42070f.jpg 1024w
,/publications/currbio_2023/gr4_lrg_hu_9b20ea009bb7abd1.jpg 1320w" sizes=100vw></picture></figure><font size=2><strong>A,</strong> Direction tuning curves for an example neuron to object (left) and surface (right) motion at three speeds. Error bars: SEM. Dashed lines: baseline activity.
<strong>B,</strong> Population histograms of the correlation between tuning curves for object (left column)/surface (right column) motion versus those of other motion types and speeds (rows). Triangles denote median values. Filled bars identify neurons with statistically significant positive correlation (p &lt; 0.05). Correlations within the same motion type (object × object or surface × surface) were higher than correlation between object and surface motion curves at all speeds.
<strong>C,</strong> Direction tuning curves for two example neurons (columns) measured with translating chromatic and achromatic bars (rows) at five luminance contrasts (see legend). Direction selectivity is evident for chromatic bars and noise patches (bottom row) but not achromatic bars.</font></p><h3 id=fig5-position-invariance-of-motion-direction-selectivity class="relative group">Fig5. Position invariance of motion direction selectivity <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig5-position-invariance-of-motion-direction-selectivity aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset="/publications/currbio_2023/gr5_lrg_hu_36b4e7ad3930d4b0.webp 330w,/publications/currbio_2023/gr5_lrg_hu_2e79ef46a659c745.webp 660w
,/publications/currbio_2023/gr5_lrg_hu_67bdeb05f05935c6.webp 1024w
,/publications/currbio_2023/gr5_lrg_hu_7265995e12285815.webp 1320w" sizes=100vw type=image/webp><img width=1625 height=1565 class="mx-auto my-0 rounded-md" alt=Fig5 loading=lazy decoding=async src=/publications/currbio_2023/gr5_lrg_hu_1d354a197abe96db.jpg srcset="/publications/currbio_2023/gr5_lrg_hu_cac942081923fe13.jpg 330w,/publications/currbio_2023/gr5_lrg_hu_1d354a197abe96db.jpg 660w
,/publications/currbio_2023/gr5_lrg_hu_13f30d21cc0328df.jpg 1024w
,/publications/currbio_2023/gr5_lrg_hu_1a3e81921953c899.jpg 1320w" sizes=100vw></picture></figure><font size=2>Responses of an example V4 neuron to object motion stimuli at five positions within the RF. Error bars: SEM. Dashed lines: baseline activity. At each position, object motion was created with three sequential stimulus patches with dX = RFd/6, dT = 50 ms in eight directions. The radial distance between the center stimulus location and the other locations was 1/3 × RFd. This neuron responded strongly at three of the five spatial positions. In all positions, the direction tuning curve was highly consistent and correlation in tuning was 0.68 (STAR Methods). Across 31 neurons studied with this paradigm, 11 exhibited statistically significant direction tuning at two or more locations. For these neurons, the mean aggregate correlation (STAR Methods) in direction tuning across locations was 0.61.</font></p><h3 id=fig6-population-decoding-of-object-motion-direction class="relative group">Fig6. Population decoding of object motion direction <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fig6-population-decoding-of-object-motion-direction aria-label=Anchor>#</a></span></h3><p><figure><picture class="mx-auto my-0 rounded-md"><source srcset="/publications/currbio_2023/gr6_lrg_hu_dded5b5e621b732b.webp 330w,/publications/currbio_2023/gr6_lrg_hu_77e149fd629c0043.webp 660w
,/publications/currbio_2023/gr6_lrg_hu_c3a3cad277b78be5.webp 1024w
,/publications/currbio_2023/gr6_lrg_hu_b6af8432d3225b2.webp 1320w" sizes=100vw type=image/webp><img width=2208 height=1964 class="mx-auto my-0 rounded-md" alt=Fig6 loading=lazy decoding=async src=/publications/currbio_2023/gr6_lrg_hu_c4675e3c5d57f0bb.jpg srcset="/publications/currbio_2023/gr6_lrg_hu_3c52c610f1646ba8.jpg 330w,/publications/currbio_2023/gr6_lrg_hu_c4675e3c5d57f0bb.jpg 660w
,/publications/currbio_2023/gr6_lrg_hu_befcf825f165e790.jpg 1024w
,/publications/currbio_2023/gr6_lrg_hu_cc37ea635c26cc22.jpg 1320w" sizes=100vw></picture></figure><font size=2><strong>A,</strong> Low-dimensional representation (first two PCs) of the activity of the direction-selective sub-population of neurons for different object motion directions (colors) for speed = 18.2°/s; this yields a systematic, robust space for deciphering motion direction.
<strong>B,</strong> The same analysis as in (A), based on the activity of non-direction-selective neurons, produces weak/non-existent patterning.
<strong>C,</strong> Projection of data for other speeds from directional neurons onto the space derived in (A). Percent correct performance of a binary decision tree for decoding the object motion direction exactly (C) or within 45° (C45) is reported for each speed.</font></p></div></section><footer class="max-w-prose pt-8 print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="group flex" href=/publications/jneurosci_2022/><span class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&larr;</span><span class="ltr:hidden rtl:inline">&rarr;</span></span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Perceptual Texture Dimensions Modulate Neuronal Response Dynamics in Visual Cortical Area V4</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2022-01-26 00:00:00 +0000 UTC">26 January 2022</time>
</span></span></a></span><span><a class="group flex text-right" href=/publications/jneurosci_2024/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Neural correlates of crowding in macaque area V4</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2024-06-12 00:00:00 +0000 UTC">12 June 2024</time>
</span></span><span class="ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[-2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&rarr;</span><span class="ltr:hidden rtl:inline">&larr;</span></span></a></span></div></div></footer></article></main><div class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12" id=to-top hidden=true><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div><footer class="py-10 print:hidden"><div class="flex items-center justify-between"><div><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Taekjun Kim</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://github.com/jpanther/congo target=_blank rel="noopener noreferrer">Congo</a></p></div><div class="flex flex-row items-center"></div></div></footer><div id=search-wrapper class="invisible fixed inset-0 z-50 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://taekjunkim.github.io/><div id=search-modal class="top-20 mx-auto flex min-h-0 w-full max-w-3xl flex-col rounded-md border border-neutral-200 bg-neutral shadow-lg dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex flex-none items-center justify-between px-2"><form class="flex min-w-0 flex-auto items-center"><div class="flex h-8 w-8 items-center justify-center text-neutral-400"><span class="icon relative inline-block px-1 align-text-bottom"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="mx-1 flex h-12 flex-auto appearance-none bg-transparent focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex h-8 w-8 items-center justify-center text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="icon relative inline-block px-1 align-text-bottom"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto overflow-auto px-2"><ul id=search-results></ul></section></div></div></div></body></html>